# ğŸ“‹ PLAN FASE 3 - Features Avanzadas del Sistema de Tools

Plan detallado con objetivos graduales e incrementales para la FASE 3.

**VersiÃ³n:** 1.0
**Fecha:** 2025-11-27
**Estado:** PlanificaciÃ³n
**Pre-requisito:** FASE 1 âœ… y FASE 2 âœ… completadas

---

## ğŸ¯ VisiÃ³n General

**Objetivo:** Transformar el sistema de Tools de "funcional" a "inteligente y escalable"

**Principio:** Desarrollo incremental - cada paso agrega valor inmediato

**DuraciÃ³n total:** 3-4 semanas (dividido en 8 hitos graduales)

---

## ğŸ“Š Estrategia de ImplementaciÃ³n

### Enfoque Gradual (Recomendado):
```
Hito 1 â†’ Valor inmediato â†’ Validar â†’ Continuar
Hito 2 â†’ MÃ¡s valor â†’ Validar â†’ Continuar
...
```

**Ventajas:**
- âœ… Cada hito es funcional y deployable
- âœ… Feedback temprano guÃ­a desarrollo
- âœ… Menor riesgo de sobre-ingenierÃ­a
- âœ… Puede detenerse en cualquier punto con valor entregado

---

## ğŸ¯ Hito 1: Auto-selecciÃ³n BÃ¡sica con LLM (3-4 dÃ­as)

**Objetivo:** LLM decide entre QueryTool, HelpTool y StatsTool

### Valor Entregado:
```
Usuario: "Â¿CuÃ¡ntos usuarios hay?"
Sistema: Detecta automÃ¡ticamente â†’ usa QueryTool
Sin necesidad de escribir /ia
```

### Tareas:

**DÃ­a 1: Infraestructura bÃ¡sica**
- [ ] Crear `src/orchestrator/tool_selector.py`
- [ ] Implementar clase `ToolSelector`
- [ ] MÃ©todo `select_tool(user_query: str) -> str`
- [ ] Integrar con PromptManager

**DÃ­a 2: Prompt de selecciÃ³n**
- [ ] Crear prompt template para selecciÃ³n
- [ ] Formato de respuesta estructurado del LLM
- [ ] ValidaciÃ³n de respuesta
- [ ] Manejo de errores

**DÃ­a 3: IntegraciÃ³n**
- [ ] Integrar en UniversalHandler
- [ ] Detectar queries sin comando
- [ ] Llamar a ToolSelector
- [ ] Ejecutar tool seleccionado

**DÃ­a 4: Testing y ajustes**
- [ ] Tests unitarios de ToolSelector
- [ ] Tests de integraciÃ³n
- [ ] Pruebas con usuarios
- [ ] Ajustar prompts segÃºn resultados

### Archivos a Crear:
```
src/orchestrator/
â”œâ”€â”€ __init__.py
â””â”€â”€ tool_selector.py       # ~150 lÃ­neas

tests/orchestrator/
â””â”€â”€ test_tool_selector.py  # ~100 lÃ­neas
```

### Criterios de Ã‰xito:
- âœ… Detecta correctamente 80%+ de queries
- âœ… Tiempo de selecciÃ³n <500ms
- âœ… Fallback graceful si falla

### Ejemplo de ImplementaciÃ³n:
```python
# src/orchestrator/tool_selector.py
class ToolSelector:
    """Selecciona el tool apropiado usando LLM."""

    async def select_tool(self, user_query: str) -> Optional[str]:
        """
        Analizar query y seleccionar tool.

        Returns:
            Nombre del tool o None si no hay coincidencia
        """
        prompt = self.prompt_manager.get_prompt(
            'tool_selection',
            query=user_query,
            available_tools=self._get_tools_descriptions()
        )

        response = await self.llm_provider.generate(prompt)
        tool_name = self._parse_tool_name(response)

        return tool_name
```

---

## ğŸ¯ Hito 2: Implementar HelpTool y StatsTool (2-3 dÃ­as)

**Objetivo:** Comandos bÃ¡sicos como tools para tener mÃ¡s opciones de selecciÃ³n

### Valor Entregado:
```
Usuario: "Â¿QuÃ© comandos puedo usar?"
Sistema: Auto-selecciona HelpTool â†’ Muestra ayuda

Usuario: "Dame estadÃ­sticas del sistema"
Sistema: Auto-selecciona StatsTool â†’ Muestra stats
```

### Tareas:

**DÃ­a 1: HelpTool**
- [ ] Crear `src/tools/builtin/help_tool.py`
- [ ] Implementar metadata y parÃ¡metros
- [ ] MÃ©todo `execute()` que lee del registry
- [ ] Auto-generar ayuda desde tools registrados
- [ ] Formatear respuesta markdown

**DÃ­a 2: StatsTool**
- [ ] Crear `src/tools/builtin/stats_tool.py`
- [ ] Obtener estadÃ­sticas del ToolOrchestrator
- [ ] Obtener estadÃ­sticas de la base de datos
- [ ] Formatear respuesta con mÃ©tricas clave
- [ ] GrÃ¡ficos ASCII opcionales

**DÃ­a 3: IntegraciÃ³n y testing**
- [ ] Registrar ambos tools en initializer
- [ ] Tests unitarios
- [ ] Tests de integraciÃ³n con ToolSelector
- [ ] DocumentaciÃ³n

### Archivos a Crear:
```
src/tools/builtin/
â”œâ”€â”€ help_tool.py           # ~100 lÃ­neas
â””â”€â”€ stats_tool.py          # ~120 lÃ­neas

tests/tools/
â”œâ”€â”€ test_help_tool.py      # ~80 lÃ­neas
â””â”€â”€ test_stats_tool.py     # ~80 lÃ­neas
```

### Criterios de Ã‰xito:
- âœ… HelpTool muestra todos los tools disponibles
- âœ… StatsTool muestra mÃ©tricas en tiempo real
- âœ… ToolSelector los detecta correctamente

### Ejemplo de ImplementaciÃ³n:
```python
# src/tools/builtin/help_tool.py
class HelpTool(BaseTool):
    """Tool que genera ayuda dinÃ¡mica desde el registry."""

    async def execute(self, user_id, params, context):
        registry = get_registry()
        tools = registry.get_all_tools()

        # Auto-generar ayuda
        help_text = "**Comandos disponibles:**\n\n"
        for tool in tools:
            help_text += f"**{tool.commands[0]}** - {tool.description}\n"

        return ToolResult.success_result(help_text)
```

---

## ğŸ¯ Hito 3: Multi-Tool Selection (2-3 dÃ­as)

**Objetivo:** LLM puede seleccionar mÃºltiples tools para una consulta

### Valor Entregado:
```
Usuario: "MuÃ©strame estadÃ­sticas y ayuda"
Sistema: Detecta 2 tools â†’ ejecuta StatsTool + HelpTool
```

### Tareas:

**DÃ­a 1: Actualizar ToolSelector**
- [ ] Modificar prompt para selecciÃ³n mÃºltiple
- [ ] Retornar lista de tools en lugar de uno solo
- [ ] Ordenar tools por prioridad
- [ ] ValidaciÃ³n de combinaciones vÃ¡lidas

**DÃ­a 2: Actualizar ToolOrchestrator**
- [ ] MÃ©todo `execute_multiple_tools()`
- [ ] Ejecutar tools en paralelo o secuencia
- [ ] Agregar resultados de mÃºltiples tools
- [ ] Formateo combinado de respuestas

**DÃ­a 3: Testing**
- [ ] Tests de selecciÃ³n mÃºltiple
- [ ] Tests de ejecuciÃ³n mÃºltiple
- [ ] Verificar performance
- [ ] Ajustar prompts

### Archivos a Modificar:
```
src/orchestrator/tool_selector.py     # +50 lÃ­neas
src/tools/tool_orchestrator.py        # +80 lÃ­neas
tests/orchestrator/test_tool_selector.py  # +60 lÃ­neas
```

### Criterios de Ã‰xito:
- âœ… Detecta correctamente mÃºltiples intents
- âœ… Ejecuta tools en orden lÃ³gico
- âœ… Combina respuestas coherentemente

---

## ğŸ¯ Hito 4: Chaining BÃ¡sico (3-4 dÃ­as)

**Objetivo:** Pasar resultados de un tool a otro

### Valor Entregado:
```
Usuario: "Consulta usuarios y genera estadÃ­sticas"
Sistema:
  1. QueryTool â†’ datos de usuarios
  2. StatsTool recibe datos â†’ calcula stats
```

### Tareas:

**DÃ­a 1: DiseÃ±o de interfaces**
- [ ] Definir formato de paso de datos entre tools
- [ ] Interfaz `ChainableToolResult`
- [ ] Metadata de compatibilidad entre tools
- [ ] Documentar contratos de datos

**DÃ­a 2: Implementar ChainExecutor**
- [ ] Crear `src/orchestrator/chain_executor.py`
- [ ] Clase `ChainExecutor`
- [ ] MÃ©todo `execute_chain(tools, initial_params)`
- [ ] Validar compatibilidad entre steps

**DÃ­a 3: IntegraciÃ³n**
- [ ] Actualizar tools para soportar chaining
- [ ] Modificar ToolOrchestrator para usar ChainExecutor
- [ ] DetecciÃ³n automÃ¡tica de oportunidades de chain

**DÃ­a 4: Testing**
- [ ] Tests unitarios de ChainExecutor
- [ ] Tests de chains especÃ­ficos
- [ ] Performance testing
- [ ] DocumentaciÃ³n de ejemplos

### Archivos a Crear:
```
src/orchestrator/
â”œâ”€â”€ chain_executor.py      # ~200 lÃ­neas
â””â”€â”€ chain_types.py         # ~50 lÃ­neas (tipos)

tests/orchestrator/
â””â”€â”€ test_chain_executor.py # ~150 lÃ­neas
```

### Criterios de Ã‰xito:
- âœ… Chain de 2-3 tools funciona correctamente
- âœ… Manejo de errores en medio del chain
- âœ… Performance aceptable (<3s por chain)

### Ejemplo:
```python
# src/orchestrator/chain_executor.py
class ChainExecutor:
    """Ejecuta tools en cadena pasando resultados."""

    async def execute_chain(
        self,
        tools: List[BaseTool],
        initial_params: Dict
    ) -> ToolResult:
        result = None

        for i, tool in enumerate(tools):
            # Primer tool usa parÃ¡metros iniciales
            if i == 0:
                params = initial_params
            else:
                # Tools subsecuentes usan resultado anterior
                params = self._transform_result_to_params(
                    result,
                    tool
                )

            result = await tool.execute(params)

            if not result.success:
                break  # Detener chain si falla

        return result
```

---

## ğŸ¯ Hito 5: ConfiguraciÃ³n de Tools por Entorno (2-3 dÃ­as)

**Objetivo:** Configurar comportamiento de tools segÃºn entorno

### Valor Entregado:
```yaml
# Dev: Debugging habilitado, lÃ­mites bajos
QueryTool:
  max_results: 10
  debug: true

# Prod: Performance optimizada, lÃ­mites altos
QueryTool:
  max_results: 100
  cache_enabled: true
```

### Tareas:

**DÃ­a 1: Sistema de configuraciÃ³n**
- [ ] Crear `src/tools/tool_config.py`
- [ ] Cargar configs desde YAML/JSON
- [ ] Modelo Pydantic para validaciÃ³n
- [ ] Configs por entorno (dev/staging/prod)

**DÃ­a 2: IntegraciÃ³n en tools**
- [ ] Modificar BaseTool para leer config
- [ ] Actualizar QueryTool con configuraciÃ³n
- [ ] Aplicar configs en otros tools
- [ ] Hot-reload de configuraciÃ³n (opcional)

**DÃ­a 3: Testing y documentaciÃ³n**
- [ ] Tests de carga de configuraciÃ³n
- [ ] Tests de validaciÃ³n
- [ ] Documentar estructura de configs
- [ ] Ejemplos de configuraciÃ³n

### Archivos a Crear:
```
src/tools/
â””â”€â”€ tool_config.py         # ~150 lÃ­neas

config/tools/
â”œâ”€â”€ dev.yaml               # Configs dev
â”œâ”€â”€ staging.yaml           # Configs staging
â””â”€â”€ prod.yaml              # Configs prod

tests/tools/
â””â”€â”€ test_tool_config.py    # ~100 lÃ­neas
```

### Criterios de Ã‰xito:
- âœ… Configs se cargan correctamente por entorno
- âœ… ValidaciÃ³n previene configuraciones invÃ¡lidas
- âœ… Tools respetan sus configuraciones

---

## ğŸ¯ Hito 6: OptimizaciÃ³n de SelecciÃ³n (2 dÃ­as)

**Objetivo:** Mejorar velocidad y precisiÃ³n del ToolSelector

### Valor Entregado:
```
Antes: 1-2 segundos para seleccionar
DespuÃ©s: <500ms para seleccionar
PrecisiÃ³n: 80% â†’ 90%+
```

### Tareas:

**DÃ­a 1: Optimizaciones**
- [ ] Cache de selecciones frecuentes
- [ ] Prompts mÃ¡s eficientes (menos tokens)
- [ ] Clasificador rÃ¡pido pre-LLM
- [ ] Paralelizar donde sea posible

**DÃ­a 2: Mejora de precisiÃ³n**
- [ ] Recopilar casos de error de selecciÃ³n
- [ ] Ajustar prompts con ejemplos
- [ ] Few-shot learning en prompt
- [ ] ValidaciÃ³n de selecciÃ³n

### Archivos a Modificar:
```
src/orchestrator/tool_selector.py     # +100 lÃ­neas
tests/orchestrator/test_tool_selector.py  # +50 lÃ­neas
```

### Criterios de Ã‰xito:
- âœ… Tiempo de selecciÃ³n <500ms en 90% casos
- âœ… PrecisiÃ³n >90% en casos comunes
- âœ… Cache hit rate >60%

---

## ğŸ¯ Hito 7: Sistema de Plugins BÃ¡sico (4-5 dÃ­as)

**Objetivo:** Cargar tools desde paquetes externos

### Valor Entregado:
```python
# Plugin externo instalable
pip install weather-tool-plugin

# Auto-descubrimiento y registro
# El bot ahora tiene WeatherTool disponible
```

### Tareas:

**DÃ­a 1: Estructura de plugins**
- [ ] Definir estructura estÃ¡ndar de plugin
- [ ] Template de plugin de ejemplo
- [ ] Documentar API de plugins
- [ ] Crear plugin de ejemplo (WeatherTool)

**DÃ­a 2: Sistema de carga**
- [ ] Crear `src/tools/plugin_manager.py`
- [ ] Auto-descubrimiento de plugins
- [ ] Carga dinÃ¡mica de mÃ³dulos
- [ ] ValidaciÃ³n de plugins

**DÃ­a 3: Seguridad y sandboxing**
- [ ] Validar plugins antes de cargar
- [ ] Sandbox bÃ¡sico para ejecuciÃ³n
- [ ] LÃ­mites de recursos
- [ ] Blacklist/whitelist de plugins

**DÃ­a 4-5: Testing y documentaciÃ³n**
- [ ] Tests de plugin manager
- [ ] Tests con plugins de ejemplo
- [ ] GuÃ­a de creaciÃ³n de plugins
- [ ] Marketplace documentation

### Archivos a Crear:
```
src/tools/
â”œâ”€â”€ plugin_manager.py      # ~250 lÃ­neas
â””â”€â”€ plugin_validator.py    # ~100 lÃ­neas

plugins/examples/
â””â”€â”€ weather_tool/          # Plugin de ejemplo
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ tool.py
    â””â”€â”€ README.md

docs/
â””â”€â”€ PLUGIN_DEVELOPMENT.md  # GuÃ­a de desarrollo
```

### Criterios de Ã‰xito:
- âœ… Plugin de ejemplo funciona
- âœ… Auto-descubrimiento funciona
- âœ… ValidaciÃ³n previene plugins maliciosos

---

## ğŸ¯ Hito 8: Tool Versioning (2-3 dÃ­as)

**Objetivo:** MÃºltiples versiones de tools coexistiendo

### Valor Entregado:
```python
# MigraciÃ³n gradual sin downtime
registry.register(QueryToolV1())  # Legacy
registry.register(QueryToolV2())  # Nueva versiÃ³n

# Usuario X sigue usando V1
# Usuario Y usa V2 automÃ¡ticamente
```

### Tareas:

**DÃ­a 1: Sistema de versiones**
- [ ] Modificar ToolRegistry para soportar versiones
- [ ] Metadata de versiÃ³n en tools
- [ ] API para registrar mÃºltiples versiones
- [ ] Estrategia de resoluciÃ³n de versiÃ³n

**DÃ­a 2: MigraciÃ³n de usuarios**
- [ ] Tabla de versiones por usuario
- [ ] API para cambiar versiÃ³n de usuario
- [ ] MigraciÃ³n gradual automÃ¡tica
- [ ] Rollback si hay problemas

**DÃ­a 3: Testing**
- [ ] Tests de coexistencia de versiones
- [ ] Tests de migraciÃ³n
- [ ] Tests de rollback
- [ ] DocumentaciÃ³n

### Archivos a Modificar/Crear:
```
src/tools/tool_registry.py         # +150 lÃ­neas
src/tools/version_manager.py       # ~200 lÃ­neas (nuevo)
tests/tools/test_versioning.py     # ~150 lÃ­neas (nuevo)
```

### Criterios de Ã‰xito:
- âœ… 2+ versiones de un tool coexisten
- âœ… MigraciÃ³n de usuarios funciona
- âœ… Rollback funciona en <5 minutos

---

## ğŸ“… Cronograma Sugerido

### Ruta RÃ¡pida (Valor Inmediato) - 2 semanas:
```
Semana 1:
â”œâ”€â”€ Hito 1: Auto-selecciÃ³n bÃ¡sica (3-4 dÃ­as)
â””â”€â”€ Hito 2: HelpTool + StatsTool (2-3 dÃ­as)

Semana 2:
â”œâ”€â”€ Hito 3: Multi-tool selection (2-3 dÃ­as)
â””â”€â”€ Hito 4: Chaining bÃ¡sico (3-4 dÃ­as)

PAUSA: Validar en producciÃ³n 1-2 semanas
```

### Ruta Completa (Features Avanzadas) - 4 semanas:
```
Semana 1-2: Hitos 1-4 (como arriba)

Semana 3:
â”œâ”€â”€ Hito 5: ConfiguraciÃ³n (2-3 dÃ­as)
â””â”€â”€ Hito 6: OptimizaciÃ³n (2 dÃ­as)

Semana 4:
â”œâ”€â”€ Hito 7: Plugins (4-5 dÃ­as)
â””â”€â”€ Hito 8: Versioning (2-3 dÃ­as)
```

---

## ğŸ¯ Puntos de DecisiÃ³n

DespuÃ©s de cada hito, evaluar:

**Â¿Continuar al siguiente hito?**
- âœ… SI: Hito actual funciona bien + hay necesidad
- â¸ï¸ PAUSAR: Validar en producciÃ³n primero
- âŒ DETENER: Ya tenemos suficiente valor

**SeÃ±ales para continuar:**
- âœ… Tests pasan >95%
- âœ… Performance es aceptable
- âœ… Usuarios estÃ¡n satisfechos
- âœ… Hay casos de uso claros para siguiente hito

**SeÃ±ales para pausar:**
- âš ï¸ Bugs importantes sin resolver
- âš ï¸ Performance degradada
- âš ï¸ Complejidad aumentando mucho
- âš ï¸ No hay casos de uso claros

---

## ğŸ“Š MÃ©tricas de Ã‰xito por Hito

| Hito | MÃ©trica Clave | Target |
|------|---------------|--------|
| 1 | PrecisiÃ³n de selecciÃ³n | >80% |
| 1 | Tiempo de selecciÃ³n | <500ms |
| 2 | Tools adicionales | 2+ tools |
| 3 | Multi-tool accuracy | >75% |
| 4 | Chains exitosos | >85% |
| 4 | Tiempo de chain | <3s |
| 5 | Config load time | <100ms |
| 6 | Selection time | <300ms |
| 7 | Plugins cargados | 1+ |
| 8 | Versiones activas | 2+ |

---

## ğŸ› ï¸ Stack TecnolÃ³gico

**Nuevos componentes:**
```
src/orchestrator/        # LÃ³gica de orquestaciÃ³n
â”œâ”€â”€ tool_selector.py     # SelecciÃ³n inteligente
â””â”€â”€ chain_executor.py    # EjecuciÃ³n en cadena

src/tools/
â”œâ”€â”€ plugin_manager.py    # GestiÃ³n de plugins
â”œâ”€â”€ tool_config.py       # ConfiguraciÃ³n
â””â”€â”€ version_manager.py   # Versionado

config/tools/            # Configuraciones
â”œâ”€â”€ dev.yaml
â”œâ”€â”€ staging.yaml
â””â”€â”€ prod.yaml

plugins/                 # Plugins externos
â””â”€â”€ examples/
```

---

## ğŸ”„ IntegraciÃ³n con GitFlow

Cada hito = feature branch:
```bash
# Hito 1
git checkout -b feature/tools-auto-selection
# ... implementar ...
git commit -m "feat(orchestrator): auto-selecciÃ³n bÃ¡sica"
git push && merge to develop

# Hito 2
git checkout -b feature/tools-help-stats
# ... implementar ...
git commit -m "feat(tools): HelpTool y StatsTool"
git push && merge to develop

# Y asÃ­ sucesivamente...
```

---

## ğŸ“š DocumentaciÃ³n a Crear

- [ ] `TOOL_SELECTOR_GUIDE.md` - CÃ³mo funciona auto-selecciÃ³n
- [ ] `CHAINING_GUIDE.md` - Crear y usar chains
- [ ] `TOOL_CONFIG_GUIDE.md` - Configurar tools
- [ ] `PLUGIN_DEVELOPMENT.md` - Crear plugins
- [ ] `VERSIONING_GUIDE.md` - Gestionar versiones

---

## âš¡ Quick Wins (Valor RÃ¡pido)

Si tienes tiempo limitado, prioriza:

**1. Hito 1 + 2 (1 semana):**
- Auto-selecciÃ³n + mÃ¡s tools
- Mayor impacto en UX
- Usuarios no necesitan recordar comandos

**2. Hito 3 + 4 (1 semana):**
- Multi-tool + chaining
- AutomatizaciÃ³n de workflows
- Valor para power users

**3. El resto segÃºn necesidad**

---

## ğŸ¯ Estado de FASE 3

**Actualmente:** PlanificaciÃ³n
**Pre-requisitos:** FASE 1 âœ… FASE 2 âœ…
**PrÃ³ximo paso:** Decidir si implementar y desde quÃ© hito empezar

**Opciones:**
1. âœ… Empezar con Hito 1 (auto-selecciÃ³n)
2. â¸ï¸ Validar FASE 2 en producciÃ³n primero
3. ğŸ“‹ Planificar mÃ¡s detalle de hitos especÃ­ficos

---

**Documento vivo - Se actualizarÃ¡ durante implementaciÃ³n**

**Ãšltima actualizaciÃ³n:** 2025-11-27
**VersiÃ³n:** 1.0
**Autor:** Sistema de Planning
