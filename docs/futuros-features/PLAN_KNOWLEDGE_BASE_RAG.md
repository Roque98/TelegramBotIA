# ðŸ“š PLAN: Knowledge Base + RAG System

Plan para transformar el agente en un "empleado capacitado" con conocimiento institucional.

**VersiÃ³n:** 1.0
**Fecha:** 2025-11-27
**Estado:** PlanificaciÃ³n
**Objetivo:** Agente con memoria empresarial que responde inteligentemente sin siempre consultar BD

---

## ðŸŽ¯ VisiÃ³n General

**Problema Actual:**
- Agente solo puede responder si consulta la BD
- No tiene conocimiento de polÃ­ticas, procesos, FAQs
- Cada pregunta requiere clasificaciÃ³n y posible query SQL

**SoluciÃ³n Propuesta:**
- Knowledge Base con informaciÃ³n institucional
- RAG (Retrieval Augmented Generation) para bÃºsqueda semÃ¡ntica
- Sistema hÃ­brido que combina: Conocimiento + BD + LLM

**Valor Entregado:**
```
Usuario: "Â¿CÃ³mo solicito vacaciones?"
Antes: âŒ No puede responder (no estÃ¡ en BD)
Ahora: âœ… "Para solicitar vacaciones debes llenar el formulario
          con 15 dÃ­as de anticipaciÃ³n..."

Usuario: "Â¿CuÃ¡ntos usuarios hay?"
Antes: âœ… Consulta BD â†’ responde
Ahora: âœ… Consulta BD â†’ responde (sin cambios)
```

---

## ðŸ“Š Estrategia de ImplementaciÃ³n

### Enfoque Incremental (3 Fases):

```
Fase 1 â†’ Knowledge Base Simple (1-2 dÃ­as)
  â†“
Fase 2 â†’ RAG System con Vectores (2-3 dÃ­as)
  â†“
Fase 3 â†’ Sistema HÃ­brido Completo (2-3 dÃ­as)
```

**Cada fase es independiente y deployable**

---

## ðŸŽ¯ FASE 1: Knowledge Base Simple (1-2 dÃ­as)

**Objetivo:** Agregar conocimiento institucional al agente mediante archivos estructurados

### Valor Entregado:

```python
Usuario: "Â¿CuÃ¡l es el horario de atenciÃ³n?"
Sistema:
  1. Busca en knowledge_base.py
  2. Encuentra: "Horario: 8am-6pm"
  3. Responde directamente (sin consultar BD)
```

### Tareas:

**DÃ­a 1: Estructura de Knowledge Base**
- [ ] Crear `src/agent/knowledge/__init__.py`
- [ ] Crear `src/agent/knowledge/company_knowledge.py`
- [ ] Definir estructura de categorÃ­as (Procesos, PolÃ­ticas, FAQs, Contactos)
- [ ] Agregar contenido inicial (10-15 entradas por categorÃ­a)
- [ ] Crear clase `KnowledgeManager` para acceder al conocimiento

**DÃ­a 2: IntegraciÃ³n con Clasificador**
- [ ] Modificar `CLASSIFICATION_V3` para incluir conocimiento
- [ ] Actualizar `QueryClassifier` para usar KnowledgeManager
- [ ] Crear nuevo tipo de respuesta: "knowledge" (ademÃ¡s de "database" y "general")
- [ ] Tests unitarios de KnowledgeManager
- [ ] Pruebas de integraciÃ³n

### Archivos a Crear:

```
src/agent/knowledge/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ company_knowledge.py      # ~200 lÃ­neas - Datos estructurados
â”œâ”€â”€ knowledge_manager.py      # ~150 lÃ­neas - LÃ³gica de bÃºsqueda simple
â””â”€â”€ knowledge_categories.py   # ~80 lÃ­neas - Enum de categorÃ­as

tests/agent/knowledge/
â””â”€â”€ test_knowledge_manager.py # ~120 lÃ­neas - Tests
```

### Ejemplo de ImplementaciÃ³n:

```python
# src/agent/knowledge/company_knowledge.py
from dataclasses import dataclass
from typing import List, Dict
from enum import Enum

class KnowledgeCategory(Enum):
    PROCESOS = "procesos"
    POLITICAS = "politicas"
    FAQS = "faqs"
    CONTACTOS = "contactos"
    SISTEMAS = "sistemas"

@dataclass
class KnowledgeEntry:
    """Entrada de conocimiento empresarial."""
    category: KnowledgeCategory
    question: str
    answer: str
    keywords: List[str]
    related_commands: List[str] = None

# Base de conocimiento
KNOWLEDGE_BASE = [
    KnowledgeEntry(
        category=KnowledgeCategory.PROCESOS,
        question="Â¿CÃ³mo solicito vacaciones?",
        answer="Para solicitar vacaciones debes: 1) Ingresar al portal de empleados, "
               "2) Llenar el formulario de vacaciones con al menos 15 dÃ­as de anticipaciÃ³n, "
               "3) Esperar aprobaciÃ³n de tu supervisor.",
        keywords=["vacaciones", "solicitar", "pedir", "dÃ­as libres", "descanso"],
        related_commands=["/help"]
    ),
    KnowledgeEntry(
        category=KnowledgeCategory.POLITICAS,
        question="Â¿CuÃ¡l es el horario de trabajo?",
        answer="El horario laboral es de Lunes a Viernes de 8:00 AM a 6:00 PM, "
               "con 1 hora de almuerzo entre 12:00 PM y 2:00 PM.",
        keywords=["horario", "hora", "entrada", "salida", "jornada"],
        related_commands=[]
    ),
    KnowledgeEntry(
        category=KnowledgeCategory.FAQS,
        question="Â¿QuÃ© hacer si olvido mi contraseÃ±a?",
        answer="Si olvidaste tu contraseÃ±a puedes: 1) Usar la opciÃ³n 'OlvidÃ© mi contraseÃ±a' "
               "en el portal, 2) Contactar al departamento de IT en la extensiÃ³n 123, "
               "3) Enviar un ticket usando /crear_ticket.",
        keywords=["contraseÃ±a", "password", "olvidÃ©", "resetear", "cambiar"],
        related_commands=["/crear_ticket"]
    ),
    KnowledgeEntry(
        category=KnowledgeCategory.CONTACTOS,
        question="Â¿CÃ³mo contacto al departamento de IT?",
        answer="Puedes contactar a IT por: ExtensiÃ³n: 123, Email: it@empresa.com, "
               "O crear un ticket usando /crear_ticket",
        keywords=["it", "sistemas", "soporte", "tÃ©cnico", "contacto"],
        related_commands=["/crear_ticket"]
    ),
    KnowledgeEntry(
        category=KnowledgeCategory.SISTEMAS,
        question="Â¿QuÃ© comandos puedo usar en el bot?",
        answer="Comandos disponibles: /help (ayuda), /ia (consultas), "
               "/stats (estadÃ­sticas), /crear_ticket (soporte). "
               "Usa /help para ver la lista completa.",
        keywords=["comandos", "ayuda", "usar", "bot", "funciones"],
        related_commands=["/help"]
    ),
]
```

```python
# src/agent/knowledge/knowledge_manager.py
class KnowledgeManager:
    """Gestor de conocimiento empresarial."""

    def __init__(self):
        self.knowledge_base = KNOWLEDGE_BASE

    def search(self, query: str, top_k: int = 3) -> List[KnowledgeEntry]:
        """
        Buscar entradas relevantes por keywords.

        Args:
            query: Consulta del usuario
            top_k: NÃºmero de resultados

        Returns:
            Lista de entradas mÃ¡s relevantes
        """
        query_lower = query.lower()
        scored_entries = []

        for entry in self.knowledge_base:
            score = 0
            # Scoring simple por keywords
            for keyword in entry.keywords:
                if keyword in query_lower:
                    score += 1

            if score > 0:
                scored_entries.append((score, entry))

        # Ordenar por score y retornar top_k
        scored_entries.sort(reverse=True, key=lambda x: x[0])
        return [entry for _, entry in scored_entries[:top_k]]

    def get_context_for_llm(self, query: str) -> str:
        """Generar contexto para agregar al prompt del LLM."""
        relevant = self.search(query, top_k=3)

        if not relevant:
            return ""

        context = "CONOCIMIENTO INSTITUCIONAL RELEVANTE:\n\n"
        for entry in relevant:
            context += f"Q: {entry.question}\n"
            context += f"A: {entry.answer}\n\n"

        return context
```

### Criterios de Ã‰xito:

- âœ… Knowledge base con 30+ entradas en 5 categorÃ­as
- âœ… KnowledgeManager encuentra entradas relevantes
- âœ… Clasificador diferencia entre "knowledge", "database" y "general"
- âœ… Respuestas instantÃ¡neas para preguntas de conocimiento
- âœ… Tests con 90%+ cobertura

---

## ðŸŽ¯ FASE 2: RAG System con Vectores (2-3 dÃ­as)

**Objetivo:** BÃºsqueda semÃ¡ntica usando embeddings (vectores)

### Valor Entregado:

```python
Usuario: "Â¿CÃ³mo pido dÃ­as libres?"  # SinÃ³nimo de "vacaciones"
Antes (keyword search): âŒ No encuentra nada
Ahora (semantic search): âœ… Encuentra entrada de vacaciones
```

### Tareas:

**DÃ­a 1: Setup de Vector Store**
- [ ] Instalar ChromaDB (`pip install chromadb`)
- [ ] Crear `VectorKnowledgeManager`
- [ ] Convertir KNOWLEDGE_BASE a vectores
- [ ] Implementar bÃºsqueda por similitud semÃ¡ntica

**DÃ­a 2: IntegraciÃ³n con OpenAI Embeddings**
- [ ] Usar OpenAI embeddings (`text-embedding-ada-002`)
- [ ] Cachear vectores para no regenerar
- [ ] Benchmark: keyword vs semantic search

**DÃ­a 3: OptimizaciÃ³n**
- [ ] HÃ­brido: semantic search + keyword fallback
- [ ] ConfiguraciÃ³n de thresholds de similitud
- [ ] Tests de performance
- [ ] DocumentaciÃ³n

### Archivos a Crear:

```
src/agent/knowledge/
â”œâ”€â”€ vector_knowledge_manager.py   # ~200 lÃ­neas
â”œâ”€â”€ embeddings_cache.py           # ~100 lÃ­neas
â””â”€â”€ vector_store.py               # ~150 lÃ­neas

tests/agent/knowledge/
â””â”€â”€ test_vector_search.py         # ~150 lÃ­neas
```

### Ejemplo de ImplementaciÃ³n:

```python
# src/agent/knowledge/vector_knowledge_manager.py
import chromadb
from chromadb.config import Settings

class VectorKnowledgeManager:
    """Gestor de conocimiento con bÃºsqueda semÃ¡ntica."""

    def __init__(self):
        # Inicializar ChromaDB local
        self.client = chromadb.Client(Settings(
            chroma_db_impl="duckdb+parquet",
            persist_directory=".chromadb"
        ))

        # Crear/obtener colecciÃ³n
        self.collection = self.client.get_or_create_collection(
            name="company_knowledge"
        )

        # Cargar knowledge base
        self._load_knowledge_base()

    def _load_knowledge_base(self):
        """Cargar entradas de conocimiento como vectores."""
        # Obtener embeddings de OpenAI
        from openai import OpenAI
        client = OpenAI()

        for idx, entry in enumerate(KNOWLEDGE_BASE):
            # Crear documento combinando pregunta y respuesta
            document = f"{entry.question} {entry.answer}"

            # Obtener embedding
            response = client.embeddings.create(
                input=document,
                model="text-embedding-ada-002"
            )
            embedding = response.data[0].embedding

            # Agregar a ChromaDB
            self.collection.add(
                embeddings=[embedding],
                documents=[document],
                metadatas=[{
                    "category": entry.category.value,
                    "question": entry.question,
                    "answer": entry.answer
                }],
                ids=[f"entry_{idx}"]
            )

    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """BÃºsqueda semÃ¡ntica por similitud de vectores."""
        # Obtener embedding de la query
        from openai import OpenAI
        client = OpenAI()

        response = client.embeddings.create(
            input=query,
            model="text-embedding-ada-002"
        )
        query_embedding = response.data[0].embedding

        # Buscar en ChromaDB
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )

        # Formatear resultados
        formatted = []
        for metadata in results['metadatas'][0]:
            formatted.append({
                'question': metadata['question'],
                'answer': metadata['answer'],
                'category': metadata['category']
            })

        return formatted
```

### Criterios de Ã‰xito:

- âœ… Vector store funcional con ChromaDB
- âœ… BÃºsqueda semÃ¡ntica con 85%+ accuracy
- âœ… Encuentra sinÃ³nimos y parÃ¡frasis
- âœ… Tiempo de respuesta <500ms
- âœ… Cache de embeddings para eficiencia

---

## ðŸŽ¯ FASE 3: Sistema HÃ­brido Completo (2-3 dÃ­as)

**Objetivo:** Orquestar mÃºltiples fuentes de conocimiento inteligentemente

### Valor Entregado:

```python
Usuario: "Â¿CuÃ¡ntos dÃ­as de vacaciones tengo disponibles?"

Sistema hÃ­brido:
  1. Buscar en knowledge base â†’ "PolÃ­ticas de vacaciones: 15 dÃ­as/aÃ±o"
  2. Consultar BD â†’ "Usuario123 ha usado 7 dÃ­as"
  3. LLM combina ambas â†’ "Tienes derecho a 15 dÃ­as por aÃ±o.
                          Has usado 7, te quedan 8 dÃ­as disponibles."
```

### Tareas:

**DÃ­a 1: Knowledge Orchestrator**
- [ ] Crear `KnowledgeOrchestrator`
- [ ] Decidir quÃ© fuentes consultar segÃºn la query
- [ ] Combinar resultados de mÃºltiples fuentes
- [ ] PriorizaciÃ³n de fuentes

**DÃ­a 2: IntegraciÃ³n Completa**
- [ ] Modificar `LLMAgent` para usar orchestrator
- [ ] Prompt engineering con mÃºltiples contextos
- [ ] Caching inteligente de resultados
- [ ] Metrics y analytics

**DÃ­a 3: OptimizaciÃ³n y Pruebas**
- [ ] A/B testing de diferentes estrategias
- [ ] OptimizaciÃ³n de costos (embeddings, tokens)
- [ ] Tests end-to-end
- [ ] DocumentaciÃ³n completa

### Archivos a Crear:

```
src/agent/orchestrator/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ knowledge_orchestrator.py     # ~300 lÃ­neas
â”œâ”€â”€ source_selector.py            # ~150 lÃ­neas
â””â”€â”€ response_combiner.py          # ~200 lÃ­neas

tests/agent/orchestrator/
â””â”€â”€ test_knowledge_orchestrator.py # ~200 lÃ­neas
```

### Ejemplo de ImplementaciÃ³n:

```python
# src/agent/orchestrator/knowledge_orchestrator.py
class KnowledgeOrchestrator:
    """Orquestador de mÃºltiples fuentes de conocimiento."""

    def __init__(
        self,
        vector_knowledge: VectorKnowledgeManager,
        db_manager: DatabaseManager,
        llm_provider: LLMProvider
    ):
        self.vector_knowledge = vector_knowledge
        self.db_manager = db_manager
        self.llm_provider = llm_provider

    async def answer_query(self, user_query: str, user_id: int) -> str:
        """
        Responder query usando mÃºltiples fuentes.

        Estrategia:
        1. Clasificar tipo de query
        2. Decidir quÃ© fuentes consultar
        3. Obtener informaciÃ³n de cada fuente
        4. Combinar y generar respuesta coherente
        """
        # 1. Clasificar query
        query_type = await self._classify_query(user_query)

        # 2. Obtener informaciÃ³n segÃºn el tipo
        sources_data = {}

        if query_type in ["knowledge", "hybrid"]:
            # Buscar en knowledge base
            knowledge_results = self.vector_knowledge.search(user_query, top_k=2)
            sources_data['knowledge'] = knowledge_results

        if query_type in ["database", "hybrid"]:
            # Consultar base de datos
            db_results = await self._query_database(user_query)
            sources_data['database'] = db_results

        # 3. Combinar y generar respuesta
        response = await self._combine_sources(
            user_query=user_query,
            sources_data=sources_data,
            query_type=query_type
        )

        return response

    async def _classify_query(self, query: str) -> str:
        """
        Clasificar query en: knowledge, database, hybrid, general.

        hybrid = necesita tanto knowledge como database
        """
        prompt = f"""
        Clasifica esta consulta:

        "{query}"

        Tipos:
        - "knowledge": Pregunta sobre polÃ­ticas/procesos/informaciÃ³n institucional
        - "database": Requiere datos especÃ­ficos de BD (conteos, registros)
        - "hybrid": Requiere AMBOS (conocimiento + datos)
        - "general": ConversaciÃ³n general

        Responde con UNA palabra.
        """

        classification = await self.llm_provider.generate(prompt, max_tokens=10)
        return classification.strip().lower()

    async def _combine_sources(
        self,
        user_query: str,
        sources_data: Dict,
        query_type: str
    ) -> str:
        """Combinar informaciÃ³n de mÃºltiples fuentes en respuesta coherente."""

        # Construir contexto combinado
        context_parts = []

        if 'knowledge' in sources_data:
            knowledge_context = "\n".join([
                f"- {entry['answer']}"
                for entry in sources_data['knowledge']
            ])
            context_parts.append(f"CONOCIMIENTO INSTITUCIONAL:\n{knowledge_context}")

        if 'database' in sources_data:
            db_context = sources_data['database']
            context_parts.append(f"DATOS DE LA BASE DE DATOS:\n{db_context}")

        full_context = "\n\n".join(context_parts)

        # Generar respuesta combinada
        prompt = f"""
        Eres un asistente de empresa. Responde la consulta del usuario usando
        la informaciÃ³n proporcionada.

        {full_context}

        Consulta del usuario: "{user_query}"

        Instrucciones:
        - Combina la informaciÃ³n de todas las fuentes de manera natural
        - Si hay datos de BD, Ãºsalos como informaciÃ³n actualizada
        - Si hay conocimiento institucional, Ãºsalo como contexto
        - SÃ© conciso pero completo

        Respuesta:
        """

        response = await self.llm_provider.generate(prompt, max_tokens=500)
        return response
```

### Criterios de Ã‰xito:

- âœ… Orchestrator decide inteligentemente quÃ© fuentes usar
- âœ… Combina conocimiento + BD coherentemente
- âœ… Respuestas 30% mÃ¡s completas que solo BD
- âœ… Costo optimizado (solo consulta lo necesario)
- âœ… Analytics de uso de cada fuente

---

## ðŸ“ˆ MÃ©tricas de Ã‰xito

### Por Fase:

**FASE 1:**
- Knowledge base con 30+ entradas
- 50% de queries simples NO requieren BD
- Tiempo de respuesta <200ms para knowledge queries

**FASE 2:**
- 85%+ accuracy en bÃºsqueda semÃ¡ntica
- Encuentra sinÃ³nimos/parÃ¡frasis correctamente
- <500ms tiempo de bÃºsqueda vectorial

**FASE 3:**
- 80% de queries clasificadas correctamente
- Combina sources en 90%+ de casos hÃ­bridos
- ReducciÃ³n de 40% en queries a BD innecesarias

---

## ðŸ› ï¸ Stack TecnolÃ³gico

### LibrerÃ­as Necesarias:

```bash
# FASE 1 - No requiere librerÃ­as adicionales
# (usa estructura de datos Python nativa)

# FASE 2 - Vector Store
pip install chromadb==0.4.22
pip install openai  # Para embeddings

# FASE 3 - Opcional
pip install langchain  # Helpers para RAG
pip install tiktoken   # Token counting
```

### Costos Estimados:

**Embeddings (OpenAI):**
- `text-embedding-ada-002`: $0.0001 per 1K tokens
- 100 entradas de knowledge (~50K tokens): $0.005
- Queries diarias (1000): ~$0.10/dÃ­a

**Total estimado:** ~$3-5/mes (muy bajo)

---

## ðŸ“š Recursos de Aprendizaje

### DocumentaciÃ³n:
- [ChromaDB Docs](https://docs.trychroma.com/)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)
- [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/)

### Ejemplos:
- [RAG from Scratch](https://github.com/langchain-ai/rag-from-scratch)
- [Building RAG Apps](https://www.pinecone.io/learn/retrieval-augmented-generation/)

---

## ðŸ”„ Mantenimiento

### ActualizaciÃ³n de Knowledge Base:

```python
# Agregar nueva entrada
new_entry = KnowledgeEntry(
    category=KnowledgeCategory.POLITICAS,
    question="Nueva polÃ­tica de home office",
    answer="...",
    keywords=[...]
)

# Re-generar vectores (FASE 2)
vector_manager.add_entry(new_entry)
```

### Monitoring:

- Dashboard de queries por tipo (knowledge/database/hybrid)
- Analytics de entradas de knowledge mÃ¡s usadas
- A/B testing de diferentes estrategias de bÃºsqueda

---

## ðŸš€ Roadmap Extendido

### Post-FASE 3 (Futuro):

1. **Memory Conversacional**
   - Recordar contexto de conversaciones previas
   - PersonalizaciÃ³n por usuario

2. **Auto-learning**
   - Detectar preguntas sin respuesta
   - Sugerir nuevas entradas de knowledge

3. **Multi-modal Knowledge**
   - PDFs, imÃ¡genes, videos
   - Knowledge externo (web scraping)

4. **Knowledge Graphs**
   - Relaciones entre entidades
   - Inferencia avanzada

---

## âœ… Checklist de Inicio

Antes de empezar FASE 1:

- [ ] Recopilar documentaciÃ³n existente (manuales, polÃ­ticas, FAQs)
- [ ] Identificar 5 categorÃ­as principales de conocimiento
- [ ] Crear lista de 30-50 preguntas frecuentes
- [ ] Definir estructura de respuestas (formato, tono)
- [ ] Setup de branch GitFlow

---

## ðŸ“ Notas Finales

**FilosofÃ­a de DiseÃ±o:**
- Empezar simple, iterar basado en feedback
- Cada fase es deployable independientemente
- Priorizar calidad sobre cantidad de entradas
- Medir, analizar, optimizar continuamente

**Riesgos y Mitigaciones:**
- **Riesgo:** Knowledge base desactualizado â†’ **MitigaciÃ³n:** Proceso de revisiÃ³n mensual
- **Riesgo:** Costos de embeddings â†’ **MitigaciÃ³n:** Caching agresivo
- **Riesgo:** Hallucinations del LLM â†’ **MitigaciÃ³n:** ValidaciÃ³n de fuentes

---

**Â¿Listo para empezar?** ðŸš€

Siguiente paso: FASE 1 - Crear estructura de Knowledge Base
