# ğŸ¯ Plan de ImplementaciÃ³n: Sistema de OrquestaciÃ³n de Tools

> **Fecha de creaciÃ³n:** 2025-11-26
> **VersiÃ³n:** 1.0
> **Estado:** Pendiente de implementaciÃ³n
> **Prioridad:** ALTA

---

## ğŸ“‹ Tabla de Contenidos

- [VisiÃ³n General](#visiÃ³n-general)
- [Objetivos](#objetivos)
- [Arquitectura Propuesta](#arquitectura-propuesta)
- [Fases de ImplementaciÃ³n](#fases-de-implementaciÃ³n)
- [Beneficios Esperados](#beneficios-esperados)
- [Riesgos y Mitigaciones](#riesgos-y-mitigaciones)
- [Referencias](#referencias)

---

## ğŸ¨ VisiÃ³n General

### SituaciÃ³n Actual

El bot tiene una arquitectura modular sÃ³lida pero carece de un sistema de orquestaciÃ³n de "tools" (capacidades/funcionalidades). Actualmente:

- âœ… Handlers bien separados
- âœ… Patrones de diseÃ±o aplicados (Strategy, Adapter, Orchestrator)
- âŒ No hay registro centralizado de capacidades
- âŒ DifÃ­cil agregar nuevas funcionalidades (5+ archivos por feature)
- âŒ No hay introspecciÃ³n de capacidades disponibles
- âŒ No se pueden habilitar/deshabilitar features dinÃ¡micamente

### VisiÃ³n Futura

Implementar un **sistema de orquestaciÃ³n de Tools** que permita:

- âœ… Agregar features con 1 solo archivo (~80 lÃ­neas)
- âœ… Descubrimiento automÃ¡tico de capacidades
- âœ… Hot-reload de funcionalidades
- âœ… Auto-documentaciÃ³n
- âœ… Testing simplificado
- âœ… Plugin system para extensiones externas

---

## ğŸ¯ Objetivos

### Objetivos Principales

1. **Extensibilidad:** Reducir complejidad de agregar features de 5+ archivos a 1 archivo
2. **Descubrimiento:** Sistema auto-documentado de capacidades disponibles
3. **Seguridad:** Centralizar autenticaciÃ³n y autorizaciÃ³n
4. **Testing:** Facilitar testing unitario de features aisladas
5. **Mantenibilidad:** Reducir acoplamiento entre componentes

### MÃ©tricas de Ã‰xito

| MÃ©trica | Antes | DespuÃ©s | Mejora |
|---------|-------|---------|--------|
| Archivos por feature | 5+ | 1 | 80% |
| LÃ­neas de cÃ³digo | 200+ | 80 | 60% |
| Tiempo de desarrollo | 4-6h | 1-2h | 66% |
| Cobertura de tests | ~0% | >80% | +80pp |
| Tiempo de onboarding | Alto | Bajo | Significativo |

---

## ğŸ—ï¸ Arquitectura Propuesta

### ğŸ”„ IntegraciÃ³n con LLM Refactorizado (YA IMPLEMENTADO)

El sistema de Tools se construirÃ¡ sobre la **arquitectura LLM ya refactorizada** (completada en v0.1.0-base), que proporciona una base sÃ³lida y modular:

#### Componentes LLM Existentes (âœ… Disponibles)

```
src/agent/
â”œâ”€â”€ llm_agent.py                    # âœ… Orquestador principal (refactorizado)
â”œâ”€â”€ providers/                       # âœ… Strategy Pattern
â”‚   â”œâ”€â”€ base_provider.py            # Interfaz comÃºn
â”‚   â”œâ”€â”€ openai_provider.py          # ImplementaciÃ³n OpenAI
â”‚   â””â”€â”€ anthropic_provider.py       # ImplementaciÃ³n Anthropic
â”œâ”€â”€ classifiers/
â”‚   â””â”€â”€ query_classifier.py         # âœ… ClasificaciÃ³n de queries
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ sql_generator.py            # âœ… GeneraciÃ³n de SQL
â”‚   â””â”€â”€ sql_validator.py            # âœ… ValidaciÃ³n y seguridad
â”œâ”€â”€ formatters/
â”‚   â””â”€â”€ response_formatter.py       # âœ… Formateo de respuestas
â””â”€â”€ prompts/
    â”œâ”€â”€ prompt_manager.py           # âœ… Sistema de prompts versionado
    â””â”€â”€ prompt_templates.py         # âœ… Templates con Jinja2
```

**Beneficios de la integraciÃ³n:**
- âœ… **Modularidad:** Componentes LLM reutilizables desde tools
- âœ… **Estrategia:** Cambio dinÃ¡mico entre OpenAI/Anthropic
- âœ… **Versionado:** Sistema de prompts con A/B testing
- âœ… **Seguridad:** ValidaciÃ³n SQL ya implementada
- âœ… **Formateo:** Respuestas consistentes y bien formateadas

---

### Estructura de Directorios

```
src/
â”œâ”€â”€ agent/                      # âœ… LLM Components (YA IMPLEMENTADO)
â”‚   â”œâ”€â”€ llm_agent.py           # Orquestador LLM
â”‚   â”œâ”€â”€ providers/             # Strategy pattern para LLMs
â”‚   â”œâ”€â”€ classifiers/           # ClasificaciÃ³n de queries
â”‚   â”œâ”€â”€ sql/                   # GeneraciÃ³n y validaciÃ³n SQL
â”‚   â”œâ”€â”€ formatters/            # Formateo de respuestas
â”‚   â””â”€â”€ prompts/               # Sistema de prompts versionado
â”‚
â”œâ”€â”€ tools/                      # Sistema de Tools (NUEVO)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tool_base.py           # Clases base abstractas
â”‚   â”œâ”€â”€ tool_registry.py       # Registro centralizado (Singleton)
â”‚   â”œâ”€â”€ tool_loader.py         # Carga dinÃ¡mica de tools
â”‚   â”œâ”€â”€ tool_config.py         # ConfiguraciÃ³n de tools
â”‚   â””â”€â”€ builtin/               # Tools incorporados
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ query_tool.py      # Consultas BD (usa LLMAgent)
â”‚       â”œâ”€â”€ help_tool.py       # Sistema de ayuda
â”‚       â”œâ”€â”€ stats_tool.py      # EstadÃ­sticas
â”‚       â”œâ”€â”€ registration_tool.py # Registro de usuarios
â”‚       â””â”€â”€ example_tool.py    # Plantilla para nuevos tools
â”‚
â”œâ”€â”€ orchestrator/              # OrquestaciÃ³n (NUEVO)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py        # Orquestador principal
â”‚   â”œâ”€â”€ execution_context.py   # Contexto de ejecuciÃ³n
â”‚   â”œâ”€â”€ tool_selector.py       # SelecciÃ³n inteligente (Fase 3)
â”‚   â””â”€â”€ chain_executor.py      # EjecuciÃ³n encadenada (Fase 3)
â”‚
â”œâ”€â”€ services/                  # Service Layer (NUEVO)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ auth_service.py        # LÃ³gica de autenticaciÃ³n
â”‚   â”œâ”€â”€ permission_service.py  # LÃ³gica de permisos
â”‚   â”œâ”€â”€ query_service.py       # LÃ³gica de queries (usa LLMAgent)
â”‚   â””â”€â”€ notification_service.py # Notificaciones (futuro)
â”‚
â””â”€â”€ bot/
    â””â”€â”€ handlers/
        â””â”€â”€ universal_handler.py # Handler universal (NUEVO)
```

### Componentes Clave

#### 1. BaseTool (Clase Base)

```python
class BaseTool(ABC):
    """Clase base abstracta para todos los tools."""

    @abstractmethod
    def get_metadata(self) -> ToolMetadata:
        """Metadatos: nombre, descripciÃ³n, comandos, permisos."""

    @abstractmethod
    def get_parameters(self) -> List[ToolParameter]:
        """ParÃ¡metros que acepta el tool."""

    @abstractmethod
    async def execute(
        self,
        user_id: int,
        params: Dict[str, Any],
        context: ExecutionContext
    ) -> ToolResult:
        """LÃ³gica de ejecuciÃ³n del tool."""
```

**Responsabilidades:**
- Definir interface consistente
- ValidaciÃ³n automÃ¡tica de parÃ¡metros
- Metadata autodocumentada

#### 2. ToolRegistry (Singleton)

```python
class ToolRegistry:
    """Registro centralizado de tools."""

    def register(self, tool: BaseTool) -> None
    def unregister(self, tool_name: str) -> None
    def get_tool_by_name(self, name: str) -> Optional[BaseTool]
    def get_tool_by_command(self, command: str) -> Optional[BaseTool]
    def get_all_tools(self) -> List[BaseTool]
    def get_tools_by_category(self, category: str) -> List[BaseTool]
    def get_user_available_tools(self, user_id: int) -> List[BaseTool]
```

**Responsabilidades:**
- Punto central de registro de tools
- Descubrimiento de capacidades
- Filtrado por permisos de usuario

#### 3. ToolOrchestrator

```python
class ToolOrchestrator:
    """Orquestador de ejecuciÃ³n de tools."""

    async def execute_command(
        self,
        user_id: int,
        command: str,
        params: Dict[str, Any],
        context: ExecutionContext
    ) -> ToolResult:
        """
        Flujo de ejecuciÃ³n:
        1. Buscar tool por comando
        2. Verificar autenticaciÃ³n
        3. Verificar permisos
        4. Validar parÃ¡metros
        5. Ejecutar tool
        6. Auditar operaciÃ³n
        """
```

**Responsabilidades:**
- Orquestar ejecuciÃ³n de tools
- Manejar auth/permisos consistentemente
- AuditorÃ­a automÃ¡tica
- Manejo centralizado de errores

#### 4. ExecutionContext

```python
class ExecutionContext:
    """Contexto de ejecuciÃ³n para tools."""

    telegram_update: Update
    telegram_context: ContextTypes.DEFAULT_TYPE
    db_manager: DatabaseManager
    llm_agent: LLMAgent  # âœ… LLMAgent refactorizado disponible

    # Acceso a componentes LLM especÃ­ficos
    @property
    def llm_provider(self) -> LLMProvider
    @property
    def query_classifier(self) -> QueryClassifier
    @property
    def sql_generator(self) -> SQLGenerator
    @property
    def prompt_manager(self) -> PromptManager

    def get_service(self, name: str) -> Any
    def get_user_id(self) -> int
    def get_chat_id(self) -> int
```

**Responsabilidades:**
- Proveer dependencias a tools
- Desacoplar tools de Telegram
- Facilitar testing con mocks
- **Exponer componentes LLM a tools** (QueryClassifier, SQLGenerator, etc.)
- **Proveer acceso al sistema de prompts versionado**

---

### ğŸ¤– Uso del LLM desde Tools

Los tools pueden aprovechar los componentes LLM refactorizados de mÃºltiples formas:

#### PatrÃ³n 1: Uso Completo del LLMAgent

```python
class QueryTool(BaseTool):
    """Tool para consultas a base de datos."""

    async def execute(self, user_id: int, params: Dict, context: ExecutionContext) -> ToolResult:
        # Usar el LLMAgent completo (orquestaciÃ³n automÃ¡tica)
        response = await context.llm_agent.process_query(params['query'])
        return ToolResult(success=True, data=response)
```

**CuÃ¡ndo usar:** Queries complejas que requieren el flujo completo (clasificar â†’ generar SQL â†’ validar â†’ ejecutar â†’ formatear)

---

#### PatrÃ³n 2: Uso de Componentes EspecÃ­ficos

```python
class SmartAnalysisTool(BaseTool):
    """Tool que analiza datos usando LLM."""

    async def execute(self, user_id: int, params: Dict, context: ExecutionContext) -> ToolResult:
        # Usar solo el SQL Generator
        schema = await context.db_manager.get_schema()
        sql = await context.sql_generator.generate_sql(params['analysis_request'], schema)

        # Validar con el SQL Validator
        is_valid, error = context.llm_agent.sql_validator.validate(sql)

        if not is_valid:
            return ToolResult(success=False, error=error)

        # Ejecutar y formatear
        results = await context.db_manager.execute_query(sql)
        formatted = context.llm_agent.response_formatter.format_query_results(
            user_query=params['analysis_request'],
            sql_query=sql,
            results=results
        )

        return ToolResult(success=True, data=formatted)
```

**CuÃ¡ndo usar:** Tools que necesitan control fino sobre el flujo de procesamiento

---

#### PatrÃ³n 3: Uso del Sistema de Prompts

```python
class ReportGeneratorTool(BaseTool):
    """Tool que genera reportes con LLM."""

    async def execute(self, user_id: int, params: Dict, context: ExecutionContext) -> ToolResult:
        # Usar el sistema de prompts versionado
        prompt = context.prompt_manager.get_prompt(
            'generate_report',
            report_type=params['type'],
            data=params['data']
        )

        # Generar reporte con el LLM provider
        report = await context.llm_provider.generate(prompt, max_tokens=2048)

        return ToolResult(success=True, data=report)
```

**CuÃ¡ndo usar:** Tools que necesitan generar texto con prompts personalizados

---

#### PatrÃ³n 4: ClasificaciÃ³n Inteligente

```python
class SmartRoutingTool(BaseTool):
    """Tool que enruta consultas segÃºn su tipo."""

    async def execute(self, user_id: int, params: Dict, context: ExecutionContext) -> ToolResult:
        # Clasificar la consulta primero
        query_type = await context.query_classifier.classify(params['query'])

        if query_type == QueryType.DATABASE:
            return await self._handle_database_query(params, context)
        elif query_type == QueryType.GENERAL:
            return await self._handle_general_query(params, context)
        else:
            return await self._handle_ambiguous_query(params, context)
```

**CuÃ¡ndo usar:** Tools que necesitan comportamiento diferente segÃºn el tipo de consulta

---

## ğŸ“… Fases de ImplementaciÃ³n

### FASE 1: Fundamentos del Sistema (1-2 semanas)

**Objetivo:** Crear la infraestructura base del sistema de Tools

#### 1.1 Crear Clases Base (3-4 dÃ­as)

**Archivos a crear:**
```
src/tools/
    __init__.py
    tool_base.py         # BaseTool, ToolMetadata, ToolParameter, ToolResult
```

**Tareas:**
- [ ] Definir `ToolMetadata` (Pydantic model)
- [ ] Definir `ToolParameter` (Pydantic model)
- [ ] Definir `ToolResult` (Pydantic model)
- [ ] Implementar `BaseTool` (clase abstracta)
- [ ] Agregar validaciÃ³n de parÃ¡metros
- [ ] Escribir tests unitarios

**Entregable:** Clases base documentadas y testeadas

**Referencia:** Ver secciÃ³n "Componentes Clave" para detalles de implementaciÃ³n

---

#### 1.2 Implementar ToolRegistry (2-3 dÃ­as)

**Archivos a crear:**
```
src/tools/
    tool_registry.py     # ToolRegistry singleton
```

**Tareas:**
- [ ] Implementar patrÃ³n Singleton
- [ ] MÃ©todo `register(tool)`
- [ ] MÃ©todo `unregister(tool_name)`
- [ ] MÃ©todo `get_tool_by_command(command)`
- [ ] MÃ©todo `get_user_available_tools(user_id, permission_checker)`
- [ ] MÃ©todo `get_tools_by_category(category)`
- [ ] Escribir tests unitarios
- [ ] Documentar API pÃºblica

**Entregable:** Registry funcional con tests

---

#### 1.3 Crear Service Layer (2-3 dÃ­as)

**Archivos a crear:**
```
src/services/
    __init__.py
    auth_service.py      # LÃ³gica de autenticaciÃ³n
    permission_service.py # LÃ³gica de permisos
```

**Tareas:**
- [ ] Extraer lÃ³gica de `UserManager` a `AuthService`
- [ ] Extraer lÃ³gica de `PermissionChecker` a `PermissionService`
- [ ] Implementar `QueryService` (preparaciÃ³n para Fase 2)
- [ ] Definir interfaces claras
- [ ] Escribir tests unitarios
- [ ] Documentar services

**Entregable:** Service layer desacoplado de handlers

---

#### 1.4 Implementar Orquestador (2-3 dÃ­as)

**Archivos a crear:**
```
src/orchestrator/
    __init__.py
    orchestrator.py      # ToolOrchestrator
    execution_context.py # ExecutionContext
```

**Tareas:**
- [ ] Implementar `ExecutionContext`
- [ ] Implementar `ToolOrchestrator.execute_command()`
- [ ] Integrar con `AuthService` y `PermissionService`
- [ ] Implementar auditorÃ­a automÃ¡tica
- [ ] Manejo de errores centralizado
- [ ] Escribir tests unitarios
- [ ] Documentar flujo de ejecuciÃ³n

**Entregable:** Orquestador completo y testeado

---

#### 1.5 Escribir Tests de IntegraciÃ³n (1-2 dÃ­as)

**Archivos a crear:**
```
tests/
    test_tools_integration.py
    test_orchestrator.py
```

**Tareas:**
- [ ] Test de registro de tools
- [ ] Test de ejecuciÃ³n completa
- [ ] Test de validaciÃ³n de permisos
- [ ] Test de manejo de errores
- [ ] Test de auditorÃ­a

**Entregable:** Suite de tests >80% coverage en componentes nuevos

---

### FASE 2: MigraciÃ³n de Funcionalidad Existente (2-3 semanas)

**Objetivo:** Migrar handlers existentes al sistema de Tools

#### 2.1 Migrar QueryHandler a QueryTool (3-4 dÃ­as)

**Archivos a crear:**
```
src/tools/builtin/
    __init__.py
    query_tool.py        # QueryTool (migrado de query_handlers.py)
```

**Tareas:**
- [ ] Crear `QueryTool` heredando de `BaseTool`
- [ ] Implementar `get_metadata()`
- [ ] Implementar `get_parameters()`
- [ ] Migrar lÃ³gica de `query_handlers.py` a `execute()`
- [ ] **Integrar con LLMAgent refactorizado (PatrÃ³n 1: uso completo)**
- [ ] Integrar con `StatusMessage`
- [ ] Escribir tests unitarios
- [ ] Probar en paralelo con handler actual

**ImplementaciÃ³n del QueryTool:**
```python
class QueryTool(BaseTool):
    """
    Tool para procesar consultas a base de datos en lenguaje natural.

    Usa el LLMAgent completo para:
    - Clasificar queries (DATABASE vs GENERAL)
    - Generar SQL automÃ¡ticamente
    - Validar seguridad del SQL
    - Ejecutar en BD
    - Formatear respuestas
    """

    def get_metadata(self) -> ToolMetadata:
        return ToolMetadata(
            name="query",
            description="Consultar base de datos en lenguaje natural",
            commands=["/ia", "/query"],
            category=ToolCategory.DATABASE,
            requires_auth=True,
            required_permissions=["/ia"]
        )

    async def execute(
        self,
        user_id: int,
        params: Dict[str, Any],
        context: ExecutionContext
    ) -> ToolResult:
        """
        Ejecutar consulta usando LLMAgent.

        Aprovecha TODA la arquitectura refactorizada:
        - QueryClassifier
        - SQLGenerator
        - SQLValidator
        - ResponseFormatter
        - PromptManager
        """
        try:
            # Usar LLMAgent completo (âœ… ya refactorizado)
            response = await context.llm_agent.process_query(params['query'])

            return ToolResult(
                success=True,
                data=response,
                metadata={'query_type': 'processed_by_llm_agent'}
            )

        except Exception as e:
            logger.error(f"Error en QueryTool: {e}")
            return ToolResult(
                success=False,
                error=str(e),
                user_friendly_error="No pude procesar tu consulta"
            )
```

**Entregable:** QueryTool funcional en paralelo con handler actual

**Ventajas de usar LLM refactorizado:**
- âœ… ImplementaciÃ³n ~30 lÃ­neas vs ~150 lÃ­neas del handler actual
- âœ… Testing mÃ¡s fÃ¡cil (mock del LLMAgent)
- âœ… Reusa toda la lÃ³gica de validaciÃ³n y seguridad
- âœ… Formateo consistente automÃ¡tico
- âœ… Sistema de prompts versionado incluido

**Notas:**
- Mantener `query_handlers.py` temporalmente
- Probar ambos en paralelo antes de eliminar handler antiguo
- La migraciÃ³n es simplificada porque el LLM **ya estÃ¡ refactorizado**

---

#### 2.2 Crear UniversalHandler (2-3 dÃ­as)

**Archivos a crear:**
```
src/bot/handlers/
    universal_handler.py  # Handler que usa orquestador
```

**Tareas:**
- [ ] Implementar `UniversalHandler`
- [ ] Integrar con `ToolOrchestrator`
- [ ] Detectar comandos vs texto libre
- [ ] Integrar con `StatusMessage`
- [ ] Manejo de errores
- [ ] Escribir tests

**Entregable:** Handler universal que delega a orquestador

---

#### 2.3 Migrar Command Handlers (3-4 dÃ­as)

**Archivos a crear:**
```
src/tools/builtin/
    help_tool.py         # /help
    stats_tool.py        # /stats
    start_tool.py        # /start
```

**Tareas:**
- [ ] Crear `HelpTool` (auto-genera ayuda desde registry)
- [ ] Crear `StatsTool`
- [ ] Crear `StartTool`
- [ ] Registrar tools en registry
- [ ] Escribir tests unitarios

**Entregable:** Comandos bÃ¡sicos como tools

---

#### 2.4 Migrar Registration Handlers (2-3 dÃ­as)

**Archivos a crear:**
```
src/tools/builtin/
    registration_tool.py  # /register, /verify
```

**Tareas:**
- [ ] Migrar flujo de registro a RegistrationTool
- [ ] Manejar estado de conversaciÃ³n
- [ ] Integrar con `AuthService`
- [ ] Escribir tests

**Entregable:** Sistema de registro como tool

---

#### 2.5 Actualizar TelegramBot (1-2 dÃ­as)

**Archivos a modificar:**
```
src/bot/telegram_bot.py
```

**Tareas:**
- [ ] Integrar `ToolOrchestrator` en inicializaciÃ³n
- [ ] Registrar `UniversalHandler`
- [ ] Registrar todos los builtin tools
- [ ] Mantener compatibilidad con handlers antiguos (temporal)
- [ ] Escribir tests de integraciÃ³n

**Entregable:** Bot usando sistema de tools

---

#### 2.6 Testing End-to-End y MigraciÃ³n Final (2-3 dÃ­as)

**Tareas:**
- [ ] Tests E2E de flujos completos
- [ ] Validar en entorno de staging
- [ ] Comparar resultados con handlers antiguos
- [ ] Eliminar handlers antiguos (si todo funciona)
- [ ] Actualizar documentaciÃ³n
- [ ] Crear tag de release

**Entregable:** Sistema de Tools funcionando en producciÃ³n

---

### FASE 3: Features Avanzadas (3-4 semanas)

**Objetivo:** Agregar capacidades avanzadas al sistema de Tools

#### 3.1 Auto-selecciÃ³n de Tool por LLM (1 semana)

**Archivos a crear:**
```
src/orchestrator/
    tool_selector.py     # SelecciÃ³n inteligente
```

**Concepto:**
El LLM decide quÃ© tool usar basado en la consulta del usuario.

**Ejemplo:**
```
Usuario: "MuÃ©strame las ventas del mes y crea un ticket si hay problemas"

LLM detecta:
1. Usar QueryTool para "ventas del mes"
2. Usar TicketTool para "crear ticket"
3. Encadenar resultados
```

**Tareas:**
- [ ] Crear prompt para selecciÃ³n de tool
- [ ] Implementar `ToolSelector`
- [ ] Integrar con `PromptManager`
- [ ] Manejar mÃºltiples tools en una consulta
- [ ] Escribir tests

**Entregable:** Sistema que selecciona tools automÃ¡ticamente

---

#### 3.2 Chaining de Tools (1 semana)

**Archivos a crear:**
```
src/orchestrator/
    chain_executor.py    # EjecuciÃ³n encadenada
```

**Concepto:**
Ejecutar mÃºltiples tools en secuencia, pasando resultados entre ellos.

**Ejemplo:**
```
1. QueryTool â†’ obtener ventas
2. AnalysisTool â†’ analizar datos
3. ReportTool â†’ generar reporte
4. EmailTool â†’ enviar reporte
```

**Tareas:**
- [ ] Implementar `ChainExecutor`
- [ ] Definir sintaxis de cadenas
- [ ] Manejar paso de datos entre tools
- [ ] Manejo de errores en cadenas
- [ ] Escribir tests

**Entregable:** Sistema de chaining funcional

---

#### 3.3 ConfiguraciÃ³n de Tools (3-4 dÃ­as)

**Archivos a crear:**
```
src/tools/
    tool_config.py       # ConfiguraciÃ³n por entorno
```

**Concepto:**
Configurar tools por entorno (dev/staging/prod).

**Ejemplo:**
```yaml
# config/tools/query_tool.yaml
dev:
  enabled: true
  max_results: 10
  cache_enabled: false

prod:
  enabled: true
  max_results: 100
  cache_enabled: true
  cache_ttl: 3600
```

**Tareas:**
- [ ] Sistema de configuraciÃ³n por entorno
- [ ] Hot-reload de configuraciÃ³n
- [ ] ValidaciÃ³n con Pydantic
- [ ] Escribir tests

**Entregable:** Tools configurables por entorno

---

#### 3.4 Sistema de Plugins (1-2 semanas)

**Archivos a crear:**
```
src/tools/
    tool_loader.py       # Carga dinÃ¡mica desde paquetes
    plugin_manager.py    # GestiÃ³n de plugins
```

**Concepto:**
Cargar tools desde paquetes externos.

**Estructura de plugin:**
```
my_plugin/
    __init__.py
    tool.py              # MyCustomTool
    requirements.txt
    README.md
```

**Tareas:**
- [ ] Sistema de descubrimiento de plugins
- [ ] Carga dinÃ¡mica de mÃ³dulos Python
- [ ] ValidaciÃ³n de plugins
- [ ] Sandboxing de plugins (seguridad)
- [ ] Marketplace de plugins (documentaciÃ³n)
- [ ] Escribir tests

**Entregable:** Sistema de plugins funcional

---

#### 3.5 Tool Versioning (3-4 dÃ­as)

**Concepto:**
MÃºltiples versiones de un tool coexistiendo.

**Ejemplo:**
```python
registry.register(QueryToolV1())  # Para usuarios antiguos
registry.register(QueryToolV2())  # Nueva versiÃ³n
registry.set_default_version('query', 'v2')
```

**Tareas:**
- [ ] Soporte para versiones mÃºltiples
- [ ] MigraciÃ³n gradual de usuarios
- [ ] A/B testing de versiones
- [ ] Deprecation warnings
- [ ] Escribir tests

**Entregable:** Sistema de versionado de tools

---

### FASE 4: Ecosystem y OptimizaciÃ³n (2-3 semanas)

**Objetivo:** Crear un ecosistema completo alrededor de Tools

#### 4.1 Tool Analytics (1 semana)

**Archivos a crear:**
```
src/tools/
    tool_analytics.py    # MÃ©tricas de uso
```

**MÃ©tricas a trackear:**
- Frecuencia de uso por tool
- Tasa de Ã©xito/error
- Tiempo de ejecuciÃ³n promedio
- Usuarios activos por tool
- Queries mÃ¡s frecuentes

**Tareas:**
- [ ] Implementar tracking de mÃ©tricas
- [ ] Integrar con sistema de logging
- [ ] Dashboard de mÃ©tricas (opcional)
- [ ] Alertas automÃ¡ticas
- [ ] Escribir tests

**Entregable:** Sistema de analytics completo

---

#### 4.2 Tool Composition (1 semana)

**Concepto:**
Crear tools complejos combinando tools simples.

**Ejemplo:**
```python
class SalesReportTool(CompositeTool):
    """Tool compuesto de QueryTool + AnalysisTool + ReportTool."""

    def __init__(self):
        self.steps = [
            QueryTool(),
            AnalysisTool(),
            ReportTool()
        ]
```

**Tareas:**
- [ ] Implementar `CompositeTool`
- [ ] Definir DSL para composiciÃ³n
- [ ] ValidaciÃ³n de composiciones
- [ ] Escribir tests

**Entregable:** Sistema de composiciÃ³n de tools

---

#### 4.3 Tool Marketplace (1 semana)

**Concepto:**
Directorio pÃºblico de tools disponibles.

**CaracterÃ­sticas:**
- BÃºsqueda de tools
- Ratings y reviews
- InstalaciÃ³n con 1 comando
- DocumentaciÃ³n generada automÃ¡ticamente

**Tareas:**
- [ ] Crear directorio de tools
- [ ] Sistema de bÃºsqueda
- [ ] GeneraciÃ³n automÃ¡tica de docs
- [ ] CLI para instalaciÃ³n
- [ ] Sitio web de marketplace (opcional)

**Entregable:** Marketplace funcional

---

## ğŸ Beneficios Esperados

### Beneficios de la IntegraciÃ³n LLM + Tools

**Sinergia ArquitectÃ³nica:**
El sistema de Tools se beneficia enormemente de tener el **LLM ya refactorizado** (v0.1.0-base):

1. **ReutilizaciÃ³n Inmediata** âœ…
   - Tools pueden usar componentes LLM probados en producciÃ³n
   - QueryClassifier, SQLGenerator, SQLValidator ya validados
   - Sistema de prompts versionado con A/B testing funcional
   - ResponseFormatter consistente en todo el sistema

2. **Desarrollo Acelerado** ğŸš€
   - Implementar QueryTool: ~30 lÃ­neas vs ~150 sin LLM refactorizado
   - No necesidad de re-implementar validaciÃ³n SQL
   - No necesidad de re-implementar formateo
   - Sistema de prompts listo para usar

3. **Consistencia Garantizada** âœ¨
   - Todas las respuestas usan el mismo ResponseFormatter
   - Todas las queries SQL pasan por el mismo SQLValidator
   - Todos los prompts vienen del PromptManager centralizado
   - Switching entre OpenAI/Anthropic transparente

4. **Testing Simplificado** ğŸ§ª
   - Mock del LLMAgent completo para tests
   - Componentes LLM ya testeados individualmente
   - Menos superficie de testing por tool
   - Mayor confianza en herencia de calidad

---

### Beneficios TÃ©cnicos

1. **Extensibilidad 10x**
   - De 5+ archivos a 1 archivo por feature
   - De 200+ lÃ­neas a ~80 lÃ­neas (o ~30 si usa LLMAgent completo)
   - De 4-6 horas a 1-2 horas

2. **Testing Mejorado**
   - Tests unitarios aislados por tool
   - Mocks fÃ¡ciles de crear (incluyendo LLMAgent)
   - Coverage >80% alcanzable
   - **Componentes LLM ya testeados** âœ…

3. **Mantenibilidad**
   - CÃ³digo mÃ¡s organizado
   - Menos acoplamiento
   - Cambios localizados
   - **LÃ³gica LLM centralizada en un solo lugar** âœ…

4. **Seguridad**
   - Auth/permisos centralizados
   - AuditorÃ­a automÃ¡tica
   - ValidaciÃ³n consistente
   - **SQLValidator reforzado con blacklist y regex** âœ…

### Beneficios de Negocio

1. **Time-to-Market**
   - Nuevas features en horas, no dÃ­as
   - IteraciÃ³n mÃ¡s rÃ¡pida
   - Feedback mÃ¡s rÃ¡pido

2. **Escalabilidad**
   - FÃ¡cil agregar capacidades
   - Sistema de plugins para terceros
   - Marketplace de extensiones

3. **Developer Experience**
   - Onboarding mÃ¡s fÃ¡cil
   - DocumentaciÃ³n auto-generada
   - Menos curva de aprendizaje

4. **Calidad**
   - Menos bugs por feature
   - Testing mÃ¡s completo
   - CÃ³digo mÃ¡s confiable

---

## âš ï¸ Riesgos y Mitigaciones

### Riesgo 1: Complejidad Inicial

**DescripciÃ³n:** El sistema de Tools agrega complejidad arquitectÃ³nica.

**Probabilidad:** ALTA
**Impacto:** MEDIO

**MitigaciÃ³n:**
- Implementar en fases incrementales
- Mantener handlers antiguos en paralelo temporalmente
- DocumentaciÃ³n extensa con ejemplos
- Training para equipo

---

### Riesgo 2: MigraciÃ³n Incompleta

**DescripciÃ³n:** Quedar con dos sistemas en paralelo indefinidamente.

**Probabilidad:** MEDIA
**Impacto:** ALTO

**MitigaciÃ³n:**
- Definir fecha lÃ­mite para migraciÃ³n
- Plan de migraciÃ³n detallado
- Tests E2E para validar paridad
- Deprecation warnings en handlers antiguos

---

### Riesgo 3: Performance

**DescripciÃ³n:** El overhead del orquestador puede afectar performance.

**Probabilidad:** BAJA
**Impacto:** MEDIO

**MitigaciÃ³n:**
- Benchmarks antes/despuÃ©s
- OptimizaciÃ³n de paths crÃ­ticos
- Caching donde sea posible
- Monitoreo de performance

---

### Riesgo 4: Breaking Changes

**DescripciÃ³n:** Cambios pueden romper funcionalidad existente.

**Probabilidad:** MEDIA
**Impacto:** ALTO

**MitigaciÃ³n:**
- Tests E2E exhaustivos
- Staging environment
- Rollback plan
- Feature flags para nueva funcionalidad

---

## ğŸ“š Referencias

### Documentos Relacionados

- [ROADMAP.md](ROADMAP.md) - Roadmap general del proyecto (incluye refactoring LLM completado)
- [PENDIENTES.md](PENDIENTES.md) - Lista de pendientes
- [COMMIT_GUIDELINES.md](COMMIT_GUIDELINES.md) - GuÃ­as de commits
- [GITFLOW.md](GITFLOW.md) - Estrategia de branches
- [docs/prompts/BEST_PRACTICES.md](docs/prompts/BEST_PRACTICES.md) - Mejores prÃ¡cticas de prompts

### Componentes LLM Refactorizados (âœ… Disponibles)

**Arquitectura Base:**
- `src/agent/llm_agent.py` - Orquestador principal (197 lÃ­neas)
- `src/agent/providers/base_provider.py` - Interface Strategy Pattern
- `src/agent/providers/openai_provider.py` - ImplementaciÃ³n OpenAI
- `src/agent/providers/anthropic_provider.py` - ImplementaciÃ³n Anthropic

**Componentes Especializados:**
- `src/agent/classifiers/query_classifier.py` - ClasificaciÃ³n DATABASE/GENERAL
- `src/agent/sql/sql_generator.py` - GeneraciÃ³n SQL con LLM
- `src/agent/sql/sql_validator.py` - ValidaciÃ³n seguridad SQL
- `src/agent/formatters/response_formatter.py` - Formateo respuestas

**Sistema de Prompts:**
- `src/agent/prompts/prompt_manager.py` - GestiÃ³n versionada (341 lÃ­neas)
- `src/agent/prompts/prompt_templates.py` - 8 versiones de prompts (336 lÃ­neas)
- `src/agent/prompts/README.md` - DocumentaciÃ³n completa

### AnÃ¡lisis TÃ©cnico

Este plan estÃ¡ basado en el anÃ¡lisis arquitectÃ³nico detallado realizado el 2025-11-26. El anÃ¡lisis completo incluye:

- RevisiÃ³n de 47 archivos Python (~8,000+ lÃ­neas)
- IdentificaciÃ³n de patrones de diseÃ±o existentes
- **Aprovechamiento del LLM refactorizado (v0.1.0-base)** âœ…
- ComparaciÃ³n con mejores prÃ¡cticas de la industria
- Estimaciones de esfuerzo basadas en experiencia

### Patrones de DiseÃ±o Utilizados

**Ya implementados (LLM):** âœ…
- **Strategy Pattern:** Para LLM providers (OpenAI/Anthropic)
- **Adapter Pattern:** Para diferentes APIs de LLM
- **Orchestrator Pattern:** LLMAgent coordina componentes
- **Template Method:** Sistema de prompts

**A implementar (Tools):**
- **Singleton Pattern:** Para ToolRegistry
- **Factory Pattern:** Para creaciÃ³n de tools
- **Template Method:** En BaseTool
- **Dependency Injection:** En ExecutionContext
- **Service Layer:** Para lÃ³gica de negocio
- **Registry Pattern:** Para descubrimiento de tools

### InspiraciÃ³n de Proyectos

- LangChain Tools System
- OpenAI Function Calling
- Rasa Action Server
- Botpress Skills
- Microsoft Bot Framework Dialogs

---

## ğŸ“Š EstimaciÃ³n Total

### Esfuerzo por Fase

| Fase | DuraciÃ³n | Complejidad | Riesgo |
|------|----------|-------------|--------|
| Fase 1: Fundamentos | 1-2 semanas | ALTA | MEDIO |
| Fase 2: MigraciÃ³n | 2-3 semanas | MEDIA | ALTO |
| Fase 3: Features Avanzadas | 3-4 semanas | ALTA | MEDIO |
| Fase 4: Ecosystem | 2-3 semanas | MEDIA | BAJO |
| **TOTAL** | **8-12 semanas** | - | - |

### Recursos Necesarios

- **Desarrollador Senior:** Full-time
- **Code Reviews:** 2-3 horas/semana
- **Testing:** 20% del tiempo de desarrollo
- **DocumentaciÃ³n:** 10% del tiempo de desarrollo

### Dependencies

**TÃ©cnicas:**
- Python 3.10+
- python-telegram-bot >= 20.0
- Pydantic >= 2.0
- SQLAlchemy >= 2.0

**De Negocio:**
- AprobaciÃ³n para cambios arquitectÃ³nicos
- Tiempo de staging/testing
- Training para equipo

---

## ğŸš€ PrÃ³ximos Pasos

### Inmediatos (Esta Semana)

1. âœ… Revisar este plan con el equipo
2. âœ… Obtener aprobaciÃ³n para Fase 1
3. âœ… Crear branch `feature/tools-system-fase1`
4. âœ… Setup de ambiente de desarrollo

### Fase 1 - Semana 1

1. âœ… Implementar `tool_base.py`
2. âœ… Escribir tests para clases base
3. âœ… Implementar `tool_registry.py`
4. âœ… Escribir tests para registry

### Fase 1 - Semana 2

1. âœ… Crear service layer
2. âœ… Implementar orquestador
3. âœ… Tests de integraciÃ³n
4. âœ… Code review y merge a develop

---

## ğŸ“ Notas de ImplementaciÃ³n

### Convenciones de CÃ³digo

- Seguir PEP 8
- Type hints obligatorios
- Docstrings en formato Google
- Tests unitarios para todo cÃ³digo nuevo
- Coverage mÃ­nimo: 80%

### Commits

Seguir [Conventional Commits](COMMIT_GUIDELINES.md):
```
feat(tools): agregar BaseTool y ToolMetadata
fix(orchestrator): corregir validaciÃ³n de permisos
docs(tools): documentar sistema de plugins
test(tools): agregar tests de integraciÃ³n
```

### Code Review

- Todos los PRs requieren revisiÃ³n
- Checklist de PR en template
- Tests deben pasar antes de merge
- DocumentaciÃ³n actualizada

### Deployment

- Fase 1: Solo en develop
- Fase 2: Staging primero, luego producciÃ³n gradual
- Fase 3+: Feature flags para habilitar gradualmente

---

## ğŸ¯ KPIs de Ã‰xito

### MÃ©tricas TÃ©cnicas

- âœ… Coverage de tests >80%
- âœ… Tiempo de desarrollo de feature <2 horas
- âœ… LÃ­neas de cÃ³digo por feature <100
- âœ… Tiempo de respuesta sin degradaciÃ³n
- âœ… 0 regresiones en funcionalidad existente

### MÃ©tricas de Producto

- âœ… 5+ nuevas features implementadas usando tools
- âœ… DocumentaciÃ³n auto-generada completa
- âœ… 0 incidentes relacionados con migraciÃ³n
- âœ… Developer satisfaction score >8/10

---

## ğŸ¯ Resumen Ejecutivo: IntegraciÃ³n LLM + Tools

### El Contexto Perfecto

Este proyecto tiene una **ventaja estratÃ©gica Ãºnica**: el LLM ya fue refactorizado completamente (v0.1.0-base) **antes** de implementar el sistema de Tools. Esto significa:

1. **Fundamentos SÃ³lidos** âœ…
   - LLMAgent modular y testeado
   - Componentes especializados (QueryClassifier, SQLGenerator, SQLValidator)
   - Sistema de prompts versionado con A/B testing
   - Strategy Pattern para mÃºltiples proveedores LLM

2. **Desarrollo Acelerado** ğŸš€
   - QueryTool: ~30 lÃ­neas de cÃ³digo (vs ~150 sin LLM refactorizado)
   - No reinventar la rueda en validaciÃ³n SQL
   - No reinventar el formateo de respuestas
   - ReutilizaciÃ³n inmediata de componentes probados

3. **Arquitectura Coherente** ğŸ—ï¸
   - Tools orquestan componentes LLM existentes
   - PatrÃ³n consistente: Tool â†’ LLMAgent â†’ Componentes
   - SeparaciÃ³n clara de responsabilidades
   - Testing simplificado con mocks

### Hoja de Ruta Integrada

```
âœ… COMPLETADO (v0.1.0-base)
â”‚
â”œâ”€â”€ Refactoring LLM
â”‚   â”œâ”€â”€ Strategy Pattern para providers
â”‚   â”œâ”€â”€ Componentes especializados
â”‚   â”œâ”€â”€ Sistema de prompts versionado
â”‚   â””â”€â”€ ValidaciÃ³n y formateo modular
â”‚
ğŸš§ EN PROGRESO (Este Plan)
â”‚
â””â”€â”€ Sistema de Tools
    â”œâ”€â”€ FASE 1: Fundamentos (1-2 semanas)
    â”‚   â”œâ”€â”€ BaseTool, ToolMetadata, ToolRegistry
    â”‚   â”œâ”€â”€ ExecutionContext (expone LLMAgent)
    â”‚   â””â”€â”€ ToolOrchestrator
    â”‚
    â”œâ”€â”€ FASE 2: MigraciÃ³n (2-3 semanas)
    â”‚   â”œâ”€â”€ QueryTool (usa LLMAgent completo)
    â”‚   â”œâ”€â”€ UniversalHandler
    â”‚   â””â”€â”€ Command Tools (help, stats, register)
    â”‚
    â”œâ”€â”€ FASE 3: Features Avanzadas (3-4 semanas)
    â”‚   â”œâ”€â”€ Auto-selecciÃ³n con LLM
    â”‚   â”œâ”€â”€ Chaining de tools
    â”‚   â””â”€â”€ Sistema de plugins
    â”‚
    â””â”€â”€ FASE 4: Ecosystem (2-3 semanas)
        â”œâ”€â”€ Analytics
        â”œâ”€â”€ Tool Composition
        â””â”€â”€ Marketplace
```

### Valor Diferencial

**Sin LLM refactorizado:**
- Implementar QueryTool: ~150 lÃ­neas + validaciÃ³n + formateo
- Re-implementar seguridad SQL en cada tool
- Sistema de prompts inconsistente
- Testing complejo de cada componente

**Con LLM refactorizado:** âœ…
- Implementar QueryTool: ~30 lÃ­neas
- ValidaciÃ³n SQL centralizada y probada
- Sistema de prompts consistente
- Testing simplificado (mock LLMAgent)

**Resultado:**
- 80% menos cÃ³digo por tool
- 66% menos tiempo de desarrollo
- Mayor calidad y consistencia
- Arquitectura escalable y mantenible

---

**Documento vivo - Se actualizarÃ¡ conforme avance la implementaciÃ³n**

**Ãšltima actualizaciÃ³n:** 2025-11-27
**PrÃ³xima revisiÃ³n:** DespuÃ©s de completar Fase 1
**VersiÃ³n:** 2.0 (IntegraciÃ³n LLM + Tools)
