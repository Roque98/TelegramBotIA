# ðŸ“ Mejores PrÃ¡cticas para Prompts

> **Ãšltima actualizaciÃ³n:** 2025-10-29
> **Sistema de Prompts:** v1.0

---

## ðŸ“‹ Tabla de Contenidos

1. [Principios Fundamentales](#principios-fundamentales)
2. [Estructura de Prompts](#estructura-de-prompts)
3. [Versionado de Prompts](#versionado-de-prompts)
4. [A/B Testing](#ab-testing)
5. [Variables en Templates](#variables-en-templates)
6. [OptimizaciÃ³n de Prompts](#optimizaciÃ³n-de-prompts)
7. [Troubleshooting](#troubleshooting)
8. [Ejemplos PrÃ¡cticos](#ejemplos-prÃ¡cticos)

---

## ðŸŽ¯ Principios Fundamentales

### 1. Claridad sobre Brevedad
- **âœ“ HACER:** Ser explÃ­cito en las instrucciones
- **âœ— EVITAR:** Instrucciones ambiguas o vagas

```python
# âŒ MAL
"Genera SQL para la pregunta"

# âœ… BIEN
"""Dado el esquema de base de datos, genera una consulta SQL segura.
SOLO usa SELECT, no modifiques datos. Responde Ãºnicamente con el SQL."""
```

### 2. SeparaciÃ³n de Concerns
- Cada prompt debe tener **un solo propÃ³sito** claro
- No mezclar clasificaciÃ³n con generaciÃ³n
- Mantener prompts modulares y reutilizables

### 3. Versionado Desde el Inicio
- **SIEMPRE** empezar con `_V1`
- Nunca modificar una versiÃ³n existente en producciÃ³n
- Crear nueva versiÃ³n para cambios significativos

### 4. Instrucciones Claras y EspecÃ­ficas
- Usar listas numeradas o con viÃ±etas
- Especificar formato de salida esperado
- Incluir ejemplos cuando sea posible

---

## ðŸ—ï¸ Estructura de Prompts

### AnatomÃ­a de un Prompt Efectivo

```
1. Contexto/Rol del sistema
2. Datos de entrada (esquema, pregunta, etc.)
3. Instrucciones especÃ­ficas
4. Restricciones y reglas
5. Formato de salida esperado
```

### Ejemplo Completo

```python
PROMPT_TEMPLATE = Template("""
[1. ROL]
Eres un experto en SQL Server especializado en generar consultas seguras.

[2. DATOS]
Esquema de base de datos:
{{ database_schema }}

Pregunta del usuario:
"{{ user_query }}"

[3. INSTRUCCIONES]
Genera una consulta SQL que:
1. Responda exactamente a la pregunta del usuario
2. Use solo tablas y columnas del esquema proporcionado
3. Sea eficiente y optimizada

[4. RESTRICCIONES]
- SOLO consultas SELECT (prohibido: INSERT, UPDATE, DELETE, DROP)
- Usar TOP {{ max_results|default(100) }} para limitar resultados
- No ejecutar procedimientos almacenados

[5. FORMATO]
Responde ÃšNICAMENTE con el cÃ³digo SQL, sin markdown ni explicaciones.

SQL:
""")
```

---

## ðŸ”„ Versionado de Prompts

### CuÃ¡ndo Crear una Nueva VersiÃ³n

| SituaciÃ³n | AcciÃ³n | Ejemplo |
|-----------|--------|---------|
| Fix de typo menor | Actualizar en v1 | "databse" â†’ "database" |
| Cambio de instrucciÃ³n | Nueva versiÃ³n (v2) | Agregar nueva regla de seguridad |
| ReformulaciÃ³n completa | Nueva versiÃ³n (v3) | Cambiar estructura del prompt |
| ExperimentaciÃ³n | Nueva versiÃ³n para A/B testing | Probar tono mÃ¡s formal vs casual |

### Nomenclatura de Versiones

```python
# Correcto âœ…
CLASSIFICATION_V1 = Template(...)
CLASSIFICATION_V2 = Template(...)
SQL_GENERATION_V1 = Template(...)
SQL_GENERATION_V2 = Template(...)

# Incorrecto âŒ
classification_prompt = Template(...)  # Sin versiÃ³n
CLASSIFICATION_FINAL = Template(...)  # Nombre ambiguo
```

### Metadata Recomendada

```python
METADATA_V2 = {
    'created_at': '2025-10-29',
    'author': 'equipo-ia',
    'changes': 'Mejorar instrucciones de seguridad SQL',
    'tested': True,
    'performance': {
        'accuracy': 0.95,
        'avg_tokens': 450
    }
}
```

---

## ðŸ§ª A/B Testing

### ConfiguraciÃ³n de A/B Testing

```python
from src.agent.prompts import get_default_manager

manager = get_default_manager()

# Ejemplo 1: 50/50 split
manager.enable_ab_test(
    'classification',
    variants={1: 0.5, 2: 0.5},
    strategy='weighted'
)

# Ejemplo 2: Gradual rollout
manager.enable_ab_test(
    'sql_generation',
    variants={1: 0.8, 2: 0.2},  # 80% v1, 20% v2
    strategy='weighted'
)

# Ejemplo 3: Round robin (testing)
manager.enable_ab_test(
    'general_response',
    variants={1: 0.33, 2: 0.33, 3: 0.34},
    strategy='round_robin'
)
```

### MÃ©tricas a Trackear

```python
# Obtener estadÃ­sticas
stats = manager.get_ab_test_stats('classification')
print(stats)
# {
#     'enabled': True,
#     'strategy': 'weighted',
#     'variants': {1: 0.5, 2: 0.5},
#     'usage': {1: 1247, 2: 1253}
# }

# AnÃ¡lisis completo
metrics = manager.get_metrics('classification')
```

### Proceso de A/B Testing

1. **PreparaciÃ³n**
   - Definir hipÃ³tesis clara
   - Crear nueva versiÃ³n del prompt
   - Configurar distribuciÃ³n inicial (ej: 90/10)

2. **EjecuciÃ³n**
   - Recolectar datos durante perÃ­odo definido
   - Monitorear mÃ©tricas clave (accuracy, latencia, costo)
   - Registrar feedback de usuarios

3. **AnÃ¡lisis**
   - Comparar mÃ©tricas entre versiones
   - Validar significancia estadÃ­stica
   - Decidir versiÃ³n ganadora

4. **Rollout**
   - Incrementar gradualmente trÃ¡fico a versiÃ³n ganadora
   - Monitorear por regresiones
   - Establecer como default

---

## ðŸŽ¨ Variables en Templates

### Variables BÃ¡sicas

```python
# Sintaxis Jinja2
prompt = manager.get_prompt(
    'sql_generation',
    user_query="Â¿CuÃ¡ntos usuarios hay?",
    database_schema=schema_text
)
```

### Variables con Valores por Defecto

```python
PROMPT_WITH_DEFAULTS = Template("""
Genera SQL con mÃ¡ximo {{ max_results|default(100) }} resultados.
Nivel de detalle: {{ detail_level|default('normal') }}
""")

# Uso
prompt = manager.get_prompt(
    'custom',
    user_query="test"
    # max_results usarÃ¡ default: 100
    # detail_level usarÃ¡ default: 'normal'
)
```

### Condicionales

```python
CONDITIONAL_PROMPT = Template("""
Pregunta: {{ user_query }}

{% if context %}
Contexto adicional: {{ context }}
{% endif %}

{% if priority == 'high' %}
âš ï¸ URGENTE: Priorizar precisiÃ³n sobre velocidad
{% else %}
Optimizar para velocidad de respuesta
{% endif %}
""")
```

### Loops

```python
MULTI_TABLE_PROMPT = Template("""
Tablas disponibles:
{% for table in tables %}
- {{ table.name }}: {{ table.description }}
  Columnas: {{ table.columns|join(', ') }}
{% endfor %}
""")
```

---

## âš¡ OptimizaciÃ³n de Prompts

### 1. Reducir Tokens

```python
# âŒ Verboso (muchos tokens)
"""
Por favor, necesito que generes una consulta SQL que sea muy segura
y que no modifique ningÃºn dato de la base de datos. Es muy importante
que uses solamente SELECT y que no uses ningÃºn comando peligroso como
DELETE o DROP TABLE porque eso serÃ­a muy malo...
"""

# âœ… Conciso y claro
"""
Genera consulta SQL de solo lectura.
SOLO SELECT - prohibido: INSERT, UPDATE, DELETE, DROP, ALTER.
"""
```

### 2. Estructura Clara

```python
# âŒ Sin estructura
"""
Dada esta base de datos genera SQL para la pregunta del usuario pero
recuerda que debe ser seguro y usar el esquema correcto ademÃ¡s de
responder solo con SQL sin markdown...
"""

# âœ… Con estructura
"""
ESQUEMA: {{ schema }}
PREGUNTA: "{{ query }}"

REGLAS:
1. Solo SELECT
2. Usar nombres exactos del esquema
3. Sin markdown en respuesta

SQL:
"""
```

### 3. Pocos-Shot Learning (Ejemplos)

```python
FEW_SHOT_PROMPT = Template("""
Genera SQL basado en estos ejemplos:

Ejemplo 1:
Pregunta: "Â¿CuÃ¡ntos usuarios hay?"
SQL: SELECT COUNT(*) as total FROM usuarios

Ejemplo 2:
Pregunta: "Lista los 5 productos mÃ¡s caros"
SQL: SELECT TOP 5 nombre, precio FROM productos ORDER BY precio DESC

Ahora tu turno:
Pregunta: "{{ user_query }}"
SQL:
""")
```

### 4. Chain of Thought (para tareas complejas)

```python
COT_PROMPT = Template("""
Analiza paso a paso:

1. Â¿QuÃ© informaciÃ³n necesita el usuario?
2. Â¿QuÃ© tablas contienen esa informaciÃ³n?
3. Â¿Se necesitan JOINs? Â¿CuÃ¡les?
4. Â¿Hay filtros o condiciones?
5. Â¿Se necesita agregaciÃ³n?

Pregunta: "{{ user_query }}"
Esquema: {{ schema }}

Razonamiento:
[Piensa aquÃ­]

SQL Final:
""")
```

---

## ðŸ› Troubleshooting

### Problema: Prompts no se cargan

```python
# Error
ValueError: No hay versiones disponibles para prompt tipo: clasificacion

# SoluciÃ³n
# 1. Verificar que el nombre estÃ© correcto (minÃºsculas, sin acentos)
manager.get_prompt('classification', ...)  # âœ…

# 2. Listar prompts disponibles
available = manager.list_prompts()
print(available)
```

### Problema: A/B testing no funciona

```python
# Verificar configuraciÃ³n
stats = manager.get_ab_test_stats('classification')
print(stats)

# Verificar que suma de pesos = 1.0
variants = {1: 0.3, 2: 0.3, 3: 0.3}  # âŒ Suma = 0.9
variants = {1: 0.33, 2: 0.33, 3: 0.34}  # âœ… Suma = 1.0
```

### Problema: Variables no se reemplazan

```python
# âŒ Variable no definida en template
PROMPT = Template("Pregunta: {{ question }}")
manager.get_prompt('test', user_query="test")  # Error: 'question' undefined

# âœ… Usar nombres consistentes
PROMPT = Template("Pregunta: {{ user_query }}")
manager.get_prompt('test', user_query="test")  # âœ…
```

---

## ðŸ’¡ Ejemplos PrÃ¡cticos

### Ejemplo 1: Crear Nuevo Prompt

```python
# 1. Agregar a prompt_templates.py
class PromptTemplates:

    DATA_VALIDATION_V1 = Template("""
Valida si los siguientes datos son correctos:

Datos: {{ data }}

Reglas de validaciÃ³n:
{% for rule in validation_rules %}
- {{ rule }}
{% endfor %}

Responde con JSON:
{
  "is_valid": true/false,
  "errors": ["lista de errores"],
  "warnings": ["lista de advertencias"]
}
""")

# 2. Usar en cÃ³digo
from src.agent.prompts import get_default_manager

manager = get_default_manager()
result = manager.get_prompt(
    'data_validation',
    data='{"email": "user@example"}',
    validation_rules=['Email debe tener @', 'Email debe tener dominio']
)
```

### Ejemplo 2: Migrar Prompt Hardcoded

```python
# âŒ ANTES (hardcoded)
def classify_urgency(message: str) -> str:
    prompt = f"""
    Â¿Este mensaje es urgente?
    Mensaje: {message}
    Responde: urgente/normal/bajo
    """
    return llm.generate(prompt)

# âœ… DESPUÃ‰S (usando sistema de prompts)
# 1. Agregar template
URGENCY_CLASSIFICATION_V1 = Template("""
Clasifica la urgencia del siguiente mensaje.

Mensaje: "{{ message }}"

Responde con UNA palabra:
- urgente: requiere atenciÃ³n inmediata
- normal: atenciÃ³n regular
- bajo: puede esperar

ClasificaciÃ³n:
""")

# 2. Refactorizar cÃ³digo
def classify_urgency(message: str) -> str:
    from src.agent.prompts import get_default_manager

    manager = get_default_manager()
    prompt = manager.get_prompt(
        'urgency_classification',
        message=message
    )
    return llm.generate(prompt)
```

### Ejemplo 3: Configurar Diferentes Versiones por Entorno

```python
# config/prompt_config.py
from src.agent.prompts import get_default_manager

def configure_prompts_for_environment(env: str):
    manager = get_default_manager()

    if env == "production":
        # Versiones estables en producciÃ³n
        manager.set_default_version('classification', 2)
        manager.set_default_version('sql_generation', 3)
        manager.set_default_version('general_response', 1)

    elif env == "staging":
        # A/B testing en staging
        manager.enable_ab_test('classification', {2: 0.7, 3: 0.3})
        manager.enable_ab_test('sql_generation', {3: 0.5, 4: 0.5})

    elif env == "development":
        # Siempre usar Ãºltimas versiones en dev
        # (comportamiento por defecto)
        pass

# main.py
from src.config.settings import settings
configure_prompts_for_environment(settings.environment)
```

---

## ðŸ“Š Checklist de Calidad de Prompts

Antes de crear una nueva versiÃ³n de prompt, verificar:

- [ ] **Claridad**: Â¿Las instrucciones son claras e inequÃ­vocas?
- [ ] **Completitud**: Â¿Incluye todos los casos edge?
- [ ] **Seguridad**: Â¿Previene comportamientos no deseados?
- [ ] **Eficiencia**: Â¿Usa la mÃ­nima cantidad de tokens necesaria?
- [ ] **Testeable**: Â¿Tiene casos de prueba definidos?
- [ ] **Versionado**: Â¿Sigue la convenciÃ³n NOMBRE_VN?
- [ ] **DocumentaciÃ³n**: Â¿EstÃ¡ documentado el cambio vs versiÃ³n anterior?
- [ ] **Variables**: Â¿Todas las variables tienen defaults o son requeridas?

---

## ðŸ”— Referencias

- [DocumentaciÃ³n Jinja2](https://jinja.palletsprojects.com/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [OpenAI Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)
- [Anthropic Prompt Library](https://docs.anthropic.com/claude/prompt-library)

---

**Ãšltima revisiÃ³n:** 2025-10-29
**Mantenido por:** Equipo de IA
**VersiÃ³n del documento:** 1.0
