"""
QueryTool - Tool para procesar consultas a base de datos en lenguaje natural.

Usa el LLMAgent completo para aprovechar toda la arquitectura refactorizada:
- QueryClassifier: Clasificaci√≥n autom√°tica DATABASE vs GENERAL
- SQLGenerator: Generaci√≥n de SQL con LLM
- SQLValidator: Validaci√≥n de seguridad
- ResponseFormatter: Formateo consistente de respuestas
"""
import logging
from typing import Any, Dict, List
from src.tools.tool_base import (
    BaseTool,
    ToolMetadata,
    ToolParameter,
    ToolResult,
    ToolCategory,
    ParameterType
)
from src.tools.execution_context import ExecutionContext

logger = logging.getLogger(__name__)


class QueryTool(BaseTool):
    """
    Tool para procesar consultas a base de datos en lenguaje natural.

    Este tool demuestra el patr√≥n 1 de uso del LLM: Uso Completo del LLMAgent.
    Delega toda la l√≥gica de procesamiento al LLMAgent refactorizado, resultando
    en una implementaci√≥n muy simple (~30 l√≠neas vs ~150 del handler antiguo).
    """

    def get_metadata(self) -> ToolMetadata:
        """Obtener metadatos del tool."""
        return ToolMetadata(
            name="query",
            description="Consultar base de datos en lenguaje natural",
            commands=["/ia", "/query"],
            category=ToolCategory.DATABASE,
            requires_auth=True,
            required_permissions=["/ia"],
            version="2.0.0",
            author="System"
        )

    def get_parameters(self) -> List[ToolParameter]:
        """Obtener par√°metros del tool."""
        return [
            ToolParameter(
                name="query",
                type=ParameterType.STRING,
                description="Consulta en lenguaje natural",
                required=True,
                validation_rules={
                    "min_length": 3,
                    "max_length": 1000
                }
            )
        ]

    async def execute(
        self,
        user_id: int,
        params: Dict[str, Any],
        context: ExecutionContext
    ) -> ToolResult:
        """
        Ejecutar consulta usando LLMAgent completo.

        El LLMAgent maneja autom√°ticamente:
        1. Clasificaci√≥n de la query (DATABASE vs GENERAL)
        2. Generaci√≥n de SQL (si aplica)
        3. Validaci√≥n de seguridad
        4. Ejecuci√≥n en base de datos
        5. Formateo de respuesta

        Args:
            user_id: ID del usuario que ejecuta
            params: Par√°metros con la query
            context: Contexto de ejecuci√≥n

        Returns:
            ToolResult con la respuesta procesada
        """
        # Validar que tenemos LLMAgent disponible
        is_valid, error = context.validate_required_components('llm_agent')
        if not is_valid:
            logger.error(f"Componente requerido no disponible: {error}")
            return ToolResult.error_result(
                error=error,
                user_friendly_error="‚ùå El sistema no est√° disponible en este momento.\n_Amber te pide disculpas_ üòî"
            )

        user_query = params['query']

        try:
            logger.info(f"Procesando query de usuario {user_id}: {user_query[:50]}...")

            # Usar LLMAgent completo - toda la magia sucede aqu√≠
            # El LLMAgent orquesta autom√°ticamente todos los componentes
            response = await context.llm_agent.process_query(user_query)

            logger.info(f"Query procesada exitosamente para usuario {user_id}")

            return ToolResult.success_result(
                data=response,
                metadata={
                    'query_length': len(user_query),
                    'user_id': user_id,
                    'tool_version': '2.0.0'
                }
            )

        except Exception as e:
            logger.error(f"Error procesando query: {e}", exc_info=True)
            return ToolResult.error_result(
                error=str(e),
                user_friendly_error=(
                    "‚ùå Ups, tuve un problema con esa consulta.\n\n"
                    "¬øPodr√≠as reformularla de otra manera?\n"
                    "_Amber est√° aqu√≠ para ayudarte_ ‚ú®"
                )
            )


class IACommandHandler:
    """
    Handler espec√≠fico para el comando /ia.

    Este handler mantiene compatibilidad con la interfaz actual de Telegram
    mientras delega la l√≥gica al sistema de Tools.
    """

    def __init__(self, tool_orchestrator, db_manager, llm_agent):
        """
        Inicializar el handler.

        Args:
            tool_orchestrator: Orquestador de tools
            db_manager: Gestor de base de datos
            llm_agent: Agente LLM
        """
        self.tool_orchestrator = tool_orchestrator
        self.db_manager = db_manager
        self.llm_agent = llm_agent
        logger.info("IACommandHandler inicializado (delegando a QueryTool)")

    async def handle_ia_command(self, update, context):
        """
        Manejar comando /ia.

        Args:
            update: Update de Telegram
            context: Context de Telegram
        """
        from src.utils.status_message import StatusMessage
        from src.tools.execution_context import ExecutionContextBuilder

        user_id = update.effective_user.id

        # Extraer la query del mensaje
        message_text = update.message.text
        # Remover el comando /ia
        query_text = message_text.replace('/ia', '').strip()

        if not query_text:
            await update.message.reply_text(
                "üí° Necesito una pregunta despu√©s de /ia\n\n"
                "**Ejemplo:** /ia ¬øCu√°ntos usuarios hay registrados?\n\n"
                "_Amber aqu√≠, lista para ayudarte_ ‚ú®"
            )
            return

        # Crear mensaje de estado
        status_msg = StatusMessage(update, context)
        await status_msg.send("üîç Amber analizando tu consulta...")

        try:
            # Construir contexto de ejecuci√≥n
            exec_context = (
                ExecutionContextBuilder()
                .with_telegram(update, context)
                .with_db_manager(self.db_manager)
                .with_llm_agent(self.llm_agent)
                .build()
            )

            # Actualizar estado
            await status_msg.update("‚ú® Procesando tu consulta...")

            # Ejecutar tool a trav√©s del orquestador
            result = await self.tool_orchestrator.execute_command(
                user_id=user_id,
                command="/ia",
                params={"query": query_text},
                context=exec_context
            )

            # Eliminar mensaje de estado
            await status_msg.delete()

            # Enviar respuesta
            if result.success:
                await update.message.reply_text(
                    result.data,
                    parse_mode='Markdown'
                )
            else:
                error_msg = result.user_friendly_error or result.error
                await update.message.reply_text(error_msg)

        except Exception as e:
            logger.error(f"Error en handle_ia_command: {e}", exc_info=True)
            await status_msg.delete()
            await update.message.reply_text(
                "‚ùå Oh no, tuve un problema procesando eso.\n\n"
                "¬øPodr√≠as intentar reformular tu pregunta?\n"
                "_Amber intenta ayudarte lo mejor posible_ üí™"
            )
